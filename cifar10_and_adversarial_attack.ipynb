{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "cifar10 and adversarial attack.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7d6d3fe66874e088df22dbf7309d0cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41846fb076314eafb65d1aaf5b1f6e1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b79adb5698144ba6b01ca434c5d41d95",
              "IPY_MODEL_ee5edf32e9ce4fb8bc3b5784c6a26e2b"
            ]
          }
        },
        "41846fb076314eafb65d1aaf5b1f6e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b79adb5698144ba6b01ca434c5d41d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cdaa26a9a1164966b51d0bb3b536118e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18a54bc061bc4ee783c137fc9c4b16f1"
          }
        },
        "ee5edf32e9ce4fb8bc3b5784c6a26e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_188179b0630e4ebe9e468a6b08dc11a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:06, 27389620.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57f69c956a5941f690397a8a5b088368"
          }
        },
        "cdaa26a9a1164966b51d0bb3b536118e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18a54bc061bc4ee783c137fc9c4b16f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "188179b0630e4ebe9e468a6b08dc11a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57f69c956a5941f690397a8a5b088368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06E-vqbxU6I0"
      },
      "source": [
        "###Adversarial Attacks###\n",
        "\n",
        "In this report Adversarial Attacks on Neural Networks are considered. \n",
        "\n",
        "- Initially three models are trained using common Convolutional Neural Network architectures. \n",
        "\n",
        "- Then using the resulting weights the Fast Gradient Sign Method is implemented.\n",
        "\n",
        "- The results are then compared for different levels of pertubation for all three architectures. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkSnNVhA6Fg7",
        "outputId": "24bcaa8e-b9d6-4e54-cace-886fc7bee6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "path = \"/content/gdrive/My Drive/Colab Notebooks\"\n",
        "os.chdir(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33SCqsPCptdY",
        "outputId": "d9b93729-9fdd-4516-c721-0656780360e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH-YddhXqxc8",
        "outputId": "3d05fceb-6bac-4503-d381-297536a7bdef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXjgsA8EU3NC"
      },
      "source": [
        "Begin by importing the neccassery libraries for defining and training a Neural Network.\n",
        "\n",
        "- Pytorch is the main library for Neural Networks it provides us with the framework for creating our Neural Network architecture and has the useful feature of automatic differentiation useful in the backpropagation algorithm. Along with this it has many other useful functions like we can use different optimizers and change batch sizes and so on. Also we can move the calcuations to the GPU this decreases training time considerably and is one of the breakthroughs for CNNs. \n",
        "\n",
        "- Torchvision is a package that allows us to import datasets that are well known relativily easily and means that we do not need to waste time preprocessing the data and it is ready to to use as input for our model. \n",
        "\n",
        "- Numpy allows us to do the numerical computations effeciently and is needed for all the matrix computations. \n",
        "\n",
        "- Matplotlib is a library that provides with a toolkit for creating visualizations and very useful for displaying images and can be used to display feature maps and filters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9byGaFAITBdT"
      },
      "source": [
        "## Importing all the libraries ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrxStl8xTBdW"
      },
      "source": [
        "# Import libraries \n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9itkLhsTBdZ"
      },
      "source": [
        "### Defining our Neural Net ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKiP_scfgVvi"
      },
      "source": [
        "\n",
        "Convolutional Neural Networks are the default choice for computer vision. Why it might be asked another ANN architecture not be used. For instance Multilayer Perceptrons. In such a case the image would need to be flattened this means even a small 28x28 image which has 784 pixels where each pixel is a feature, our input layer needs 784 inputs if we even have a few layers it is evident that the number of connections and thus weights will be quite large and the amount of time that is taken to train such a model will be execesive. \n",
        "\n",
        "Convolutional Neural Nets make use of the heirachical structure of the data in this case images. They are made of low level features like lines which combine together to form shapes. They have many useful feautures that make them suitable for image classification. There structure is not too different from ANNs however there are some key differences namely, the convolutional layer, pooling layers and drop out layers. Each serve a different purpose and together they are very powerful and unrivaled in the area of computer vision. \n",
        "\n",
        "Part of their strength is that the data requires very little preprocessing and the filters learn by themselves the important features this is very different from normal neural nets where they are largely uninterpretible and we can not clearly see what decisions the model is making here we can clearly see in the filters and feature maps what our model \"sees\" and what it uses to identify certain things.  \n",
        "\n",
        "There structure is roughly as follows. An input layer which unlike MLP does not need to be flattened so it can take a 2D input for a greyscale image like MNIST or 3D for a 3 channel image RGB such as CIFAR-10. The output layer has the number of classes. The interesting part is the hidden layers. A Neural Net is convolutional if at least one of its hidden layers is convolutional. What follows a convolutional layer is normally a pooling layer. There are different arrangements and combinations of convolutional and pooling layers, they can even be stacked ontop of eachother. We also have dropout layers they serve the purpose of preventing overfitting by randomly shutting of certain neurons during testing. Before the final layer we then have some fully connected layers and then the output layer which depends on the data in this case softmax for classification. \n",
        "\n",
        "I will now go through each of the different types of layers in detail:\n",
        "\n",
        "- Input Layer \n",
        "\n",
        "This is the first layer in our Neural Net its size is determined by the size of the input. If we limit the discussion to images that the resolution of the image determines the input layer. It is possible the layer be larger say if padding was used. \n",
        "\n",
        "- Convolutional Layer \n",
        "\n",
        "In a CNN at least one of the hidden layers is a convolutional layer. The convolutional layer takes is not fully connected it is connected to a limited number of neurons from the previous layer. This is for several reasons. Images tend to be made up low level feautures which combine together. Therefore it is only neccassery to capture a portion of input which can be combined and used to create high level features at a later stage. CNN's becuase they are not fully connected self regularize. Convolutional layers work by selecting a filter size then finding weights for these filters. \n",
        "\n",
        "- Pooling Layer \n",
        "\n",
        "Pooling layers are similar to Convolutional layers they work by aggregating the output of a layer using some function, the most popular is max pool. This takes the pixel with the highest intensity. This is a dimension reduction technique. \n",
        "\n",
        "- Dropout Layer \n",
        "\n",
        "Dropout layers are used to regulurize our network i.e to stop it from overfitting. It works by stopping the network having an over reliance on any single neuron. It can be implemented in several different ways. We can shut off neurons during the training stage selectivly or we can randomly do this also. \n",
        "\n",
        "- Fully connected regime \n",
        "\n",
        "As part of a CNN's architecture the last layers are usually dense. These final fully connected layers combine all the lower level features found by the convolutional layer. \n",
        "\n",
        "- Output Layer\n",
        "\n",
        "This is the final layer in our network and in a classification problem its size is determined by the number of classes. \n",
        "\n",
        "- Batch Normalization\n",
        "\n",
        "This helps with the problem of exploding and vanishing gradients a problem in deep networks. Batch normalization is often combined with convolutional layers and allows us to use saturating activation functions. \n",
        "\n",
        "Hyperparameters \n",
        "\n",
        "- Stride \n",
        "\n",
        "This determines the change from the input to the output size. \n",
        "\n",
        "- Padding \n",
        "\n",
        "These are extra pixels put around the image to maintain the input and output size at each layer.\n",
        "There is zero padding and just using the nearest value. \n",
        "\n",
        "- filter size \n",
        "\n",
        "The filter size is what a neuron sees some times called the receptive field. \n",
        "\n",
        "Other features\n",
        "\n",
        "- Loss function \n",
        "\n",
        "The loss or cost function penalizes incorrect predictions. We wish to minimize this so the model makes as few mistakes as possible. \n",
        "\n",
        "\n",
        "- Activation function \n",
        "\n",
        "The function like sigmoid or relu that takes a weighted sum as its input then outputs a number. Its choice is very important and should be carefully considered. \n",
        "\n",
        "- Optimizer\n",
        "\n",
        "The optimizer is what helps us to minimize the loss function. Often an anlytic solution does not exist or is computationaly difficult to compute. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1ynNZXJdkQI"
      },
      "source": [
        "#Net#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW8g_pOAc5lW"
      },
      "source": [
        "# Neural Network Architecture \n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding = 1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, 3, padding = 1)\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, 3, padding = 1)\n",
        "        self.maxpool = nn.MaxPool2d(2, 2)\n",
        "        self.avgpool = nn.AvgPool2d(2, 2)\n",
        "        self.globalavgpool = nn.AvgPool2d(8, 8)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.dropout50 = nn.Dropout(0.5)\n",
        "        self.dropout10 = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(256, 10)\n",
        "\n",
        "# Forward function    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.dropout10(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.avgpool(x)\n",
        "        x = self.dropout10(x)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.globalavgpool(x)\n",
        "        x = self.dropout50(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC7E7_z1rD8V"
      },
      "source": [
        "Above is a custom architecture the main feautures of this are \n",
        "\n",
        "- Three stacked convolutional kernals. Stacked convolutional kernals are very useful and serve two main purposes. Dicounting the first layer if we wish to increase the receptive field of a kernal we should stack two layers on top of eachother. Also it adds non-linearity to the model making it more powerful. \n",
        "\n",
        "- Pooling Layers it uses three time average,max and global average pooling. \n",
        "\n",
        "- Uses Relu activation function  this is the default activation function and very fast to compute. It does have some issues but they are mostly addressed by its many variants such as leaky Relu and PRelu\n",
        "\n",
        "- Before the last layer there is a dropout layer to prevent overfitting then the input in flattenend (requires 1D input) so it can be ready for the fully connected layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paeK9-tTddtv"
      },
      "source": [
        "#LeNet-5#\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4D1NJvITBda"
      },
      "source": [
        "# Neural Net architecture for lenet-5\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "\n",
        "# Forward function \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpKRHHDlrPEP"
      },
      "source": [
        "Above is the architecture of the lenet-5 Neural Net. It is very simple and consists of only a few hidden layers. It is very famous and was used by the banks to check the digits on hand written cheques. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqyOxCQydXD8"
      },
      "source": [
        "#ResNet#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKJuyM0bdI9j"
      },
      "source": [
        "# Neural Net architecture for ResNet\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McCx0I7LrSxe"
      },
      "source": [
        "This is the ResNet architecture. It is somewhat more complicated then the preceding Networks. Also it is not a simple FeedFoward Network, where layers are only connected to preceeding layers. We have skip layers now. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZba06glTBdd"
      },
      "source": [
        "## Define FGSM function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6fMf332KLgH"
      },
      "source": [
        "An Adversarial Attack is an attempt to cause a classifier to misclassify an image that it is presented with. Whilst Neural Networks are incredibly powerful and have unrivalled classification rates it is remarkably simple to fool them to misclassify the image they are shown.Part of the problem with Neural Nets is there interpretability.  Humans can perceive things in a way that Neural Nets cannot, but do not think humans cannot be tricked there are numerous illusions that many will be familiar with.  This is a problem if we consider the modern world and AI for example self-driving cars. \n",
        "\n",
        "There are several cases or types of attack that can be considered. For instance are we interested in the output class of the image or do we simply require that the image is misclassified ?\n",
        "\n",
        "Do we have information such as the architecture and weights of the model we wish to fool, or do we just know the output and input classes?\n",
        "\n",
        "The approach we pursue will depend on the answers to the above and are summarised below.\n",
        "Targeted (Here we want to fool the classifier to a specific class) / Untargeted (We do not care about the output class just that it is different from the ground truth) / Black box (Nothing about the model weights or its architecture is known only the corresponding inputs and outputs) / White box (All the details of the model are known) \n",
        "\n",
        "A single channel 28x28 image is made up of 784 pixels each pixel is represented by its intensity 0-255. \n",
        "We wish to fool a classifier subject to the requirement that any alteration that we make to the image be minimal. A norm that penalises changes is needed. Some commonly used are the p norm or l norm. \n",
        "The perturbation applied should be imperceptible, that is a human looking at the image should not be able to see the input has been tampered with.\n",
        "A successful attack is one which fools the classifier without being noticed by the user. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wdlW53-rYCQ"
      },
      "source": [
        "Here is the fgsm function from the pytorch tutorial. \n",
        "\n",
        "The function takes three arguments the base image epsilon the amount of pertubation and the data_gradient. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPg2dRPMTBde"
      },
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5GiEiaJTBdh"
      },
      "source": [
        "## Importing Data and Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK8OvYzlsE3i"
      },
      "source": [
        "Torchvision is used to import the data and is used so that we do not need to worry about the preprocessing of the data. It is a very useful tool especially if you are interested in quickly validating your model using a well known dataset.  \n",
        "\n",
        "Data Augamentation \n",
        "\n",
        "- To train a deep Neural Net a large amount of labelled training data is required in the literature around 100K is an often referenced number. This sometimes is often not possible so data augamentation can be used to artificially increase the size of the training data. This is done by applying transformations, rotations and changing the contrast of images. It can increase the size of the data set by around 50x and makes the network invariant to small changes. It regularizes the model and stops overfitting. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XUcEjFWwnH8"
      },
      "source": [
        "import imgaug.augmenters as iaa\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "pic_size = 32\n",
        "aug = iaa.Sequential([\n",
        "        iaa.Affine(\n",
        "        scale=(0.8, 1.2), \n",
        "        rotate=(-5, 5), \n",
        "        order=[0],),\n",
        "        iaa.PadToFixedSize(pic_size, pic_size),\n",
        "        iaa.CropToFixedSize(pic_size, pic_size),\n",
        "        iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=1.0)),\n",
        "        iaa.Sometimes(0.5, iaa.SaltAndPepper(0.06, per_channel=True)),\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_OIU2E2wnVq"
      },
      "source": [
        "class CIFAR10_iaa(datasets.CIFAR10):\n",
        "    def __getitem__(self, idx):\n",
        "        pil, target = super().__getitem__(idx)\n",
        "        img = aug(image=np.array(pil)) / 255\n",
        "        return img.transpose((2, 0, 1)), target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPKLx5ioTBdi",
        "outputId": "6f3ba185-2828-4f80-f704-6c0307373c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "d7d6d3fe66874e088df22dbf7309d0cf",
            "41846fb076314eafb65d1aaf5b1f6e1b",
            "b79adb5698144ba6b01ca434c5d41d95",
            "ee5edf32e9ce4fb8bc3b5784c6a26e2b",
            "cdaa26a9a1164966b51d0bb3b536118e",
            "18a54bc061bc4ee783c137fc9c4b16f1",
            "188179b0630e4ebe9e468a6b08dc11a6",
            "57f69c956a5941f690397a8a5b088368"
          ]
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Enter the training and testing batch size \n",
        "train_batch_size = 100\n",
        "test_batch_size = 1\n",
        "\n",
        "# To use autgrad we must convert to tensor\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),])\n",
        "\n",
        "# Import CIFAR10 and specify batch size \n",
        "\n",
        "# Training data\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Testing data\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=test_batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Specify the classes in the dataset \n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7d6d3fe66874e088df22dbf7309d0cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiUDjav-TBdm"
      },
      "source": [
        "## Training of model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEKwo-zbTBdm"
      },
      "source": [
        "### Init Net and Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnUi83FXTBdn"
      },
      "source": [
        "# Use the GPU if available to speed up training \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cuda:2\")\n",
        "net = Net().train().to(device)\n",
        "lenet = LeNet().train().to(device)\n",
        "resnet = ResNet18().train().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW01rjiSW-EH"
      },
      "source": [
        "###Summary of the architecture for all three networks###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbBhX_FpchHx",
        "outputId": "46747ce5-0357-47b3-a1b8-9d89b02324da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "summary(net,(3,32,32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "            Conv2d-2           [-1, 64, 32, 32]          36,928\n",
            "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
            "           Dropout-4           [-1, 64, 16, 16]               0\n",
            "            Conv2d-5          [-1, 128, 16, 16]          73,856\n",
            "            Conv2d-6          [-1, 128, 16, 16]         147,584\n",
            "         AvgPool2d-7            [-1, 128, 8, 8]               0\n",
            "           Dropout-8            [-1, 128, 8, 8]               0\n",
            "            Conv2d-9            [-1, 256, 8, 8]         295,168\n",
            "           Conv2d-10            [-1, 256, 8, 8]         590,080\n",
            "        AvgPool2d-11            [-1, 256, 1, 1]               0\n",
            "          Dropout-12            [-1, 256, 1, 1]               0\n",
            "           Linear-13                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 1,147,978\n",
            "Trainable params: 1,147,978\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.13\n",
            "Params size (MB): 4.38\n",
            "Estimated Total Size (MB): 6.52\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBBJHHJLcu_0",
        "outputId": "64a306d0-64c2-41df-f396-121055da0c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "summary(lenet,(3,32,32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             456\n",
            "            Conv2d-2           [-1, 16, 10, 10]           2,416\n",
            "            Linear-3                  [-1, 120]          48,120\n",
            "            Linear-4                   [-1, 84]          10,164\n",
            "            Linear-5                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.05\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.30\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRnFy7x6c3b5",
        "outputId": "2136c517-c73c-41b2-eafa-a537b6359a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(resnet,(3,32,32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
            "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.25\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 53.89\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK1y3JpdTBdq"
      },
      "source": [
        "### Selecting the loss function and optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO_1hCNcMsPF"
      },
      "source": [
        "Selecting the optimiser is very important on large data sets using gradient descent or batch gradient descent is not feasible so we must select another. The default is Stochastic Gradient Descent here Adam is used there are others available and can be experimented with such as RMSPROP. Adam is an adaptive variant of Stochastic Gradient Descent. It utilises different learning rates for different parameters.\n",
        "\n",
        "Also we can see cross entropy loss is used. Cross entropy measures and penalizes our model depending on whether its prediction matches the base truth and the strength of this prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWWa3tO_TBdr"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_net = optim.Adam(net.parameters(), lr=0.001)\n",
        "optimizer_lenet = optim.Adam(lenet.parameters(), lr=0.001)\n",
        "optimizer_resnet = optim.Adam(resnet.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdjms6miTBdv"
      },
      "source": [
        "### Training and saving the weights of the each model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GmLoCeKTBdw",
        "outputId": "ceea9650-0203-4cd5-e402-e02633baf312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.\n",
        "    for i, data in enumerate(trainloader):\n",
        "        \n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer_net.zero_grad()\n",
        "        \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_net.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print('[%d, %5d] loss: %.4f' %(epoch + 1, (i+1)*train_batch_size, loss.item()))\n",
        "\n",
        "print('Finished Training')\n",
        "torch.save(net.state_dict(), './cifar10_net.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 10000] loss: 2.0458\n",
            "[1, 20000] loss: 1.9338\n",
            "[1, 30000] loss: 1.7630\n",
            "[1, 40000] loss: 1.6730\n",
            "[1, 50000] loss: 1.5610\n",
            "[2, 10000] loss: 1.6417\n",
            "[2, 20000] loss: 1.5879\n",
            "[2, 30000] loss: 1.4433\n",
            "[2, 40000] loss: 1.7247\n",
            "[2, 50000] loss: 1.4355\n",
            "[3, 10000] loss: 1.3106\n",
            "[3, 20000] loss: 1.4207\n",
            "[3, 30000] loss: 1.3591\n",
            "[3, 40000] loss: 1.2209\n",
            "[3, 50000] loss: 1.2326\n",
            "[4, 10000] loss: 1.1032\n",
            "[4, 20000] loss: 1.2065\n",
            "[4, 30000] loss: 1.0471\n",
            "[4, 40000] loss: 1.1625\n",
            "[4, 50000] loss: 1.0990\n",
            "[5, 10000] loss: 0.9588\n",
            "[5, 20000] loss: 1.0296\n",
            "[5, 30000] loss: 0.9145\n",
            "[5, 40000] loss: 0.9370\n",
            "[5, 50000] loss: 0.9488\n",
            "[6, 10000] loss: 0.8890\n",
            "[6, 20000] loss: 0.9637\n",
            "[6, 30000] loss: 0.8035\n",
            "[6, 40000] loss: 0.9849\n",
            "[6, 50000] loss: 0.9404\n",
            "[7, 10000] loss: 0.8142\n",
            "[7, 20000] loss: 1.1104\n",
            "[7, 30000] loss: 0.9531\n",
            "[7, 40000] loss: 0.9807\n",
            "[7, 50000] loss: 0.8908\n",
            "[8, 10000] loss: 0.8111\n",
            "[8, 20000] loss: 0.8205\n",
            "[8, 30000] loss: 0.9020\n",
            "[8, 40000] loss: 0.7845\n",
            "[8, 50000] loss: 0.9036\n",
            "[9, 10000] loss: 0.7346\n",
            "[9, 20000] loss: 0.8296\n",
            "[9, 30000] loss: 0.6964\n",
            "[9, 40000] loss: 0.7144\n",
            "[9, 50000] loss: 0.7744\n",
            "[10, 10000] loss: 0.5861\n",
            "[10, 20000] loss: 0.7946\n",
            "[10, 30000] loss: 0.7901\n",
            "[10, 40000] loss: 0.8372\n",
            "[10, 50000] loss: 0.7396\n",
            "Finished Training\n",
            "CPU times: user 1min 43s, sys: 1min 5s, total: 2min 49s\n",
            "Wall time: 2min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhGjT-WPeXX5",
        "outputId": "b45df82b-334f-4b93-9dd8-8aea6ce65b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.\n",
        "    for i, data in enumerate(trainloader):\n",
        "        \n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer_lenet.zero_grad()\n",
        "        \n",
        "        outputs = lenet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_lenet.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print('[%d, %5d] loss: %.4f' %(epoch + 1, (i+1)*train_batch_size, loss.item()))\n",
        "\n",
        "print('Finished Training')\n",
        "torch.save(lenet.state_dict(), './cifar10_lenet.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 10000] loss: 1.8518\n",
            "[1, 20000] loss: 1.7383\n",
            "[1, 30000] loss: 1.6483\n",
            "[1, 40000] loss: 1.6215\n",
            "[1, 50000] loss: 1.4112\n",
            "[2, 10000] loss: 1.4330\n",
            "[2, 20000] loss: 1.4523\n",
            "[2, 30000] loss: 1.4943\n",
            "[2, 40000] loss: 1.5443\n",
            "[2, 50000] loss: 1.4060\n",
            "[3, 10000] loss: 1.3764\n",
            "[3, 20000] loss: 1.4191\n",
            "[3, 30000] loss: 1.3587\n",
            "[3, 40000] loss: 1.1262\n",
            "[3, 50000] loss: 1.3903\n",
            "[4, 10000] loss: 1.2965\n",
            "[4, 20000] loss: 1.4262\n",
            "[4, 30000] loss: 1.3086\n",
            "[4, 40000] loss: 1.3197\n",
            "[4, 50000] loss: 1.2511\n",
            "[5, 10000] loss: 1.4237\n",
            "[5, 20000] loss: 1.1058\n",
            "[5, 30000] loss: 1.2847\n",
            "[5, 40000] loss: 1.2106\n",
            "[5, 50000] loss: 1.1819\n",
            "[6, 10000] loss: 1.2585\n",
            "[6, 20000] loss: 1.1997\n",
            "[6, 30000] loss: 1.1290\n",
            "[6, 40000] loss: 1.1281\n",
            "[6, 50000] loss: 1.2251\n",
            "[7, 10000] loss: 1.1976\n",
            "[7, 20000] loss: 1.1328\n",
            "[7, 30000] loss: 1.0363\n",
            "[7, 40000] loss: 1.2337\n",
            "[7, 50000] loss: 1.3378\n",
            "[8, 10000] loss: 1.0624\n",
            "[8, 20000] loss: 1.2918\n",
            "[8, 30000] loss: 1.2419\n",
            "[8, 40000] loss: 0.9230\n",
            "[8, 50000] loss: 1.2838\n",
            "[9, 10000] loss: 1.2371\n",
            "[9, 20000] loss: 1.1191\n",
            "[9, 30000] loss: 1.1912\n",
            "[9, 40000] loss: 1.1939\n",
            "[9, 50000] loss: 1.2049\n",
            "[10, 10000] loss: 1.0736\n",
            "[10, 20000] loss: 1.1226\n",
            "[10, 30000] loss: 0.9468\n",
            "[10, 40000] loss: 1.1734\n",
            "[10, 50000] loss: 1.0058\n",
            "Finished Training\n",
            "CPU times: user 26 s, sys: 3.4 s, total: 29.4 s\n",
            "Wall time: 1min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2qS-QkxeXJ9",
        "outputId": "631de382-bd59-4457-e383-3a13a4f06330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.\n",
        "    for i, data in enumerate(trainloader):\n",
        "        \n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer_resnet.zero_grad()\n",
        "        \n",
        "        outputs = resnet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_resnet.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print('[%d, %5d] loss: %.4f' %(epoch + 1, (i+1)*train_batch_size, loss.item()))\n",
        "\n",
        "print('Finished Training')\n",
        "torch.save(resnet.state_dict(), './cifar10_resnet.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 10000] loss: 1.4620\n",
            "[1, 20000] loss: 1.4030\n",
            "[1, 30000] loss: 1.3101\n",
            "[1, 40000] loss: 1.0417\n",
            "[1, 50000] loss: 1.0489\n",
            "[2, 10000] loss: 0.8957\n",
            "[2, 20000] loss: 0.7791\n",
            "[2, 30000] loss: 0.8098\n",
            "[2, 40000] loss: 0.7184\n",
            "[2, 50000] loss: 0.7826\n",
            "[3, 10000] loss: 0.6976\n",
            "[3, 20000] loss: 0.6272\n",
            "[3, 30000] loss: 0.6257\n",
            "[3, 40000] loss: 0.6254\n",
            "[3, 50000] loss: 0.6538\n",
            "[4, 10000] loss: 0.5311\n",
            "[4, 20000] loss: 0.5357\n",
            "[4, 30000] loss: 0.5554\n",
            "[4, 40000] loss: 0.5098\n",
            "[4, 50000] loss: 0.4877\n",
            "[5, 10000] loss: 0.2592\n",
            "[5, 20000] loss: 0.4607\n",
            "[5, 30000] loss: 0.3631\n",
            "[5, 40000] loss: 0.3851\n",
            "[5, 50000] loss: 0.4417\n",
            "[6, 10000] loss: 0.2543\n",
            "[6, 20000] loss: 0.2595\n",
            "[6, 30000] loss: 0.4753\n",
            "[6, 40000] loss: 0.2287\n",
            "[6, 50000] loss: 0.3357\n",
            "[7, 10000] loss: 0.1933\n",
            "[7, 20000] loss: 0.1758\n",
            "[7, 30000] loss: 0.2064\n",
            "[7, 40000] loss: 0.2163\n",
            "[7, 50000] loss: 0.2206\n",
            "[8, 10000] loss: 0.1105\n",
            "[8, 20000] loss: 0.1598\n",
            "[8, 30000] loss: 0.1630\n",
            "[8, 40000] loss: 0.1436\n",
            "[8, 50000] loss: 0.1663\n",
            "[9, 10000] loss: 0.0968\n",
            "[9, 20000] loss: 0.1351\n",
            "[9, 30000] loss: 0.1210\n",
            "[9, 40000] loss: 0.0932\n",
            "[9, 50000] loss: 0.2000\n",
            "[10, 10000] loss: 0.0934\n",
            "[10, 20000] loss: 0.0482\n",
            "[10, 30000] loss: 0.0933\n",
            "[10, 40000] loss: 0.1395\n",
            "[10, 50000] loss: 0.1193\n",
            "Finished Training\n",
            "CPU times: user 6min 43s, sys: 4min 22s, total: 11min 6s\n",
            "Wall time: 11min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efNOMWi6TBdy"
      },
      "source": [
        "### Load weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM_4kItLTBdz",
        "outputId": "20cd0249-2ad5-4442-efbe-2fcbd3a21264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Loading the weights of the pretrained models\n",
        "net.load_state_dict(torch.load('./cifar10_net.pth', map_location='cpu'))\n",
        "lenet.load_state_dict(torch.load('./cifar10_lenet.pth', map_location='cpu'))\n",
        "resnet.load_state_dict(torch.load('./cifar10_resnet.pth', map_location='cpu'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQcq1buFTBd3"
      },
      "source": [
        "### Evaluate the mode & fix the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7EBNe3gTBd3"
      },
      "source": [
        "net.eval()\n",
        "for p in net.parameters():\n",
        "    p.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w3kS_6pfzfm"
      },
      "source": [
        "lenet.eval()\n",
        "for p in lenet.parameters():\n",
        "    p.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqDus0GsfzQh"
      },
      "source": [
        "resnet.eval()\n",
        "for p in resnet.parameters():\n",
        "    p.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ3JlHBeTBd6"
      },
      "source": [
        "### Accuracy of the Net model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRV81qDyTBd6",
        "outputId": "4a5b3d6a-56a5-4780-fdce-3e7c618b0310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        " \n",
        "print('Accuracy of the Net network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        " \n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(test_batch_size):\n",
        "            label = labels[i]\n",
        "#           class_correct[label] += c[i].item()\n",
        "            class_correct[label] += c.item()\n",
        "            class_total[label] += 1\n",
        " \n",
        " \n",
        "for i in range(10):\n",
        "    print('Net Network: Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the Net network on the 10000 test images: 77 %\n",
            "Net Network: Accuracy of plane : 86 %\n",
            "Net Network: Accuracy of   car : 93 %\n",
            "Net Network: Accuracy of  bird : 61 %\n",
            "Net Network: Accuracy of   cat : 57 %\n",
            "Net Network: Accuracy of  deer : 75 %\n",
            "Net Network: Accuracy of   dog : 64 %\n",
            "Net Network: Accuracy of  frog : 84 %\n",
            "Net Network: Accuracy of horse : 79 %\n",
            "Net Network: Accuracy of  ship : 87 %\n",
            "Net Network: Accuracy of truck : 82 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6-DoCK9egJW"
      },
      "source": [
        "### Accuracy of the LeNet-5 model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwwDrDocf_PZ",
        "outputId": "11467e67-fadb-435d-d65b-aaa76bd12172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = lenet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        " \n",
        "print('Accuracy of the LeNet network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        " \n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = lenet(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(test_batch_size):\n",
        "            label = labels[i]\n",
        "#           class_correct[label] += c[i].item()\n",
        "            class_correct[label] += c.item()\n",
        "            class_total[label] += 1\n",
        " \n",
        " \n",
        "for i in range(10):\n",
        "    print('LeNet Network: Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the LeNet network on the 10000 test images: 59 %\n",
            "LeNet Network: Accuracy of plane : 73 %\n",
            "LeNet Network: Accuracy of   car : 74 %\n",
            "LeNet Network: Accuracy of  bird : 51 %\n",
            "LeNet Network: Accuracy of   cat : 42 %\n",
            "LeNet Network: Accuracy of  deer : 43 %\n",
            "LeNet Network: Accuracy of   dog : 44 %\n",
            "LeNet Network: Accuracy of  frog : 63 %\n",
            "LeNet Network: Accuracy of horse : 61 %\n",
            "LeNet Network: Accuracy of  ship : 73 %\n",
            "LeNet Network: Accuracy of truck : 65 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTah70K7ekoo"
      },
      "source": [
        "### Accuracy of the ResNet model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghet3eVf--h",
        "outputId": "dfb0e512-fecd-41d2-a2e6-6fc71b80a5c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        " \n",
        "print('Accuracy of the ResNet network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        " \n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(test_batch_size):\n",
        "            label = labels[i]\n",
        "#           class_correct[label] += c[i].item()\n",
        "            class_correct[label] += c.item()\n",
        "            class_total[label] += 1\n",
        " \n",
        " \n",
        "for i in range(10):\n",
        "    print('ResNet Network: Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the ResNet network on the 10000 test images: 82 %\n",
            "ResNet Network: Accuracy of plane : 84 %\n",
            "ResNet Network: Accuracy of   car : 90 %\n",
            "ResNet Network: Accuracy of  bird : 81 %\n",
            "ResNet Network: Accuracy of   cat : 68 %\n",
            "ResNet Network: Accuracy of  deer : 72 %\n",
            "ResNet Network: Accuracy of   dog : 70 %\n",
            "ResNet Network: Accuracy of  frog : 87 %\n",
            "ResNet Network: Accuracy of horse : 93 %\n",
            "ResNet Network: Accuracy of  ship : 84 %\n",
            "ResNet Network: Accuracy of truck : 93 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj7m2maSVYRn"
      },
      "source": [
        "Interestingly all three networks they had simarlaly poor performance on the bird,cat,deer and dog classes. It is only possible to speculate why this may be as with only this information it cannot be known for certain ,as it appears in all three there it is likely some underlying cause is responsible. A possible approach would be to check the correlation between these classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBEgtoCGTBd9"
      },
      "source": [
        "### Adversarial Attack using FGSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5RCESxBTBd9"
      },
      "source": [
        "# Here we define the function that tests our model\n",
        "def test( model, device, test_loader, epsilon ):\n",
        "\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        # Send the data and label to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Forward pass the data through the model\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        # Zero all existing gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Collect datagrad\n",
        "        data_grad = data.grad.data\n",
        "\n",
        "        # Call FGSM Attack\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "        else:\n",
        "            # Save some adv examples for visualization later\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(test_loader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adv_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbtCXyKfgRC5"
      },
      "source": [
        "### Here we run the attacks and evaluate the accuracy for different values of epsilon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSRDapUsTBeB",
        "outputId": "0a0dc008-81dd-4b29-cc7a-c0b64e058474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "%%time\n",
        "accuracies_net = []\n",
        "examples_net = []\n",
        "epsilons_net = [0, .01, .02, .03, .04, .05, .06,.07,.08,.09,.1]\n",
        "# Run test for each epsilon\n",
        "# testloader batchsize should be 1\n",
        "for eps in epsilons_net:\n",
        "    acc, ex = test(net, device, testloader, eps)\n",
        "    accuracies_net.append(acc)\n",
        "    examples_net.append(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 7739 / 10000 = 0.7739\n",
            "Epsilon: 0.01\tTest Accuracy = 4071 / 10000 = 0.4071\n",
            "Epsilon: 0.02\tTest Accuracy = 2080 / 10000 = 0.208\n",
            "Epsilon: 0.03\tTest Accuracy = 1156 / 10000 = 0.1156\n",
            "Epsilon: 0.04\tTest Accuracy = 777 / 10000 = 0.0777\n",
            "Epsilon: 0.05\tTest Accuracy = 595 / 10000 = 0.0595\n",
            "Epsilon: 0.06\tTest Accuracy = 542 / 10000 = 0.0542\n",
            "Epsilon: 0.07\tTest Accuracy = 507 / 10000 = 0.0507\n",
            "Epsilon: 0.08\tTest Accuracy = 506 / 10000 = 0.0506\n",
            "Epsilon: 0.09\tTest Accuracy = 520 / 10000 = 0.052\n",
            "Epsilon: 0.1\tTest Accuracy = 507 / 10000 = 0.0507\n",
            "CPU times: user 6min 11s, sys: 40.8 s, total: 6min 52s\n",
            "Wall time: 7min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvFSugaJi5IY",
        "outputId": "1c7a9da0-0a47-4cf0-95c3-bd9b6b7754ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "%%time\n",
        "accuracies_net2 = []\n",
        "examples_net2 = []\n",
        "epsilons_net2 = [0, .02, .04, .06, .08, .1, .12,.14,.16,.18,.2]\n",
        "\n",
        "# Run test for each epsilon\n",
        "# testloader batchsize should be 1\n",
        "for eps in epsilons_net2:\n",
        "    acc, ex = test(net, device, testloader, eps)\n",
        "    accuracies_net2.append(acc)\n",
        "    examples_net2.append(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 7739 / 10000 = 0.7739\n",
            "Epsilon: 0.02\tTest Accuracy = 2080 / 10000 = 0.208\n",
            "Epsilon: 0.04\tTest Accuracy = 777 / 10000 = 0.0777\n",
            "Epsilon: 0.06\tTest Accuracy = 542 / 10000 = 0.0542\n",
            "Epsilon: 0.08\tTest Accuracy = 506 / 10000 = 0.0506\n",
            "Epsilon: 0.1\tTest Accuracy = 507 / 10000 = 0.0507\n",
            "Epsilon: 0.12\tTest Accuracy = 553 / 10000 = 0.0553\n",
            "Epsilon: 0.14\tTest Accuracy = 587 / 10000 = 0.0587\n",
            "Epsilon: 0.16\tTest Accuracy = 629 / 10000 = 0.0629\n",
            "Epsilon: 0.18\tTest Accuracy = 694 / 10000 = 0.0694\n",
            "Epsilon: 0.2\tTest Accuracy = 728 / 10000 = 0.0728\n",
            "CPU times: user 6min 12s, sys: 40.5 s, total: 6min 52s\n",
            "Wall time: 7min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roIpHiVHkjt2",
        "outputId": "9f1083b0-e8d3-40e4-dd2b-cd2e96883ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "%%time\n",
        "accuracies_net3 = []\n",
        "examples_net3 = []\n",
        "epsilons_net3 = [0, .05, .1, .15, .2, .25, .3,.35,.4,.45,.5]\n",
        "\n",
        "# Run test for each epsilon\n",
        "# testloader batchsize should be 1\n",
        "for eps in epsilons_net3:\n",
        "    acc, ex = test(net, device, testloader, eps)\n",
        "    accuracies_net3.append(acc)\n",
        "    examples_net3.append(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 7739 / 10000 = 0.7739\n",
            "Epsilon: 0.05\tTest Accuracy = 595 / 10000 = 0.0595\n",
            "Epsilon: 0.1\tTest Accuracy = 507 / 10000 = 0.0507\n",
            "Epsilon: 0.15\tTest Accuracy = 598 / 10000 = 0.0598\n",
            "Epsilon: 0.2\tTest Accuracy = 728 / 10000 = 0.0728\n",
            "Epsilon: 0.25\tTest Accuracy = 825 / 10000 = 0.0825\n",
            "Epsilon: 0.3\tTest Accuracy = 851 / 10000 = 0.0851\n",
            "Epsilon: 0.35\tTest Accuracy = 875 / 10000 = 0.0875\n",
            "Epsilon: 0.4\tTest Accuracy = 903 / 10000 = 0.0903\n",
            "Epsilon: 0.45\tTest Accuracy = 919 / 10000 = 0.0919\n",
            "Epsilon: 0.5\tTest Accuracy = 944 / 10000 = 0.0944\n",
            "CPU times: user 6min 13s, sys: 40.8 s, total: 6min 54s\n",
            "Wall time: 7min 37s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFh6g91Wh-IB",
        "outputId": "97b6a59f-b44c-49dd-85b2-5a1adcdee44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "accuracies_lenet = []\n",
        "examples_lenet = []\n",
        "epsilons_lenet = [0, .01, .02, .03, .04, .05, .06,.07,.08,.09,.1]\n",
        "\n",
        "# Run test for each epsilon\n",
        "# testloader batchsize should be 1\n",
        "for eps in epsilons_lenet:\n",
        "    acc, ex = test(lenet, device, testloader, eps)\n",
        "    accuracies_lenet.append(acc)\n",
        "    examples_lenet.append(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 5931 / 10000 = 0.5931\n",
            "Epsilon: 0.01\tTest Accuracy = 3037 / 10000 = 0.3037\n",
            "Epsilon: 0.02\tTest Accuracy = 1501 / 10000 = 0.1501\n",
            "Epsilon: 0.03\tTest Accuracy = 757 / 10000 = 0.0757\n",
            "Epsilon: 0.04\tTest Accuracy = 415 / 10000 = 0.0415\n",
            "Epsilon: 0.05\tTest Accuracy = 242 / 10000 = 0.0242\n",
            "Epsilon: 0.06\tTest Accuracy = 146 / 10000 = 0.0146\n",
            "Epsilon: 0.07\tTest Accuracy = 91 / 10000 = 0.0091\n",
            "Epsilon: 0.08\tTest Accuracy = 67 / 10000 = 0.0067\n",
            "Epsilon: 0.09\tTest Accuracy = 55 / 10000 = 0.0055\n",
            "Epsilon: 0.1\tTest Accuracy = 36 / 10000 = 0.0036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvOXzSQuh95_",
        "outputId": "bd22a63b-5c69-411d-d6e0-97076f46671d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "accuracies_resnet = []\n",
        "examples_resnet = []\n",
        "epsilons_resnet = [0, .01, .02, .03, .04, .05, .06,.07,.08,.09,.1]\n",
        "\n",
        "# Run test for each epsilon\n",
        "# testloader batchsize should be 1\n",
        "for eps in epsilons_resnet:\n",
        "    acc, ex = test(resnet, device, testloader, eps)\n",
        "    accuracies_resnet.append(acc)\n",
        "    examples_resnet.append(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 8256 / 10000 = 0.8256\n",
            "Epsilon: 0.01\tTest Accuracy = 1580 / 10000 = 0.158\n",
            "Epsilon: 0.02\tTest Accuracy = 324 / 10000 = 0.0324\n",
            "Epsilon: 0.03\tTest Accuracy = 125 / 10000 = 0.0125\n",
            "Epsilon: 0.04\tTest Accuracy = 78 / 10000 = 0.0078\n",
            "Epsilon: 0.05\tTest Accuracy = 69 / 10000 = 0.0069\n",
            "Epsilon: 0.06\tTest Accuracy = 74 / 10000 = 0.0074\n",
            "Epsilon: 0.07\tTest Accuracy = 92 / 10000 = 0.0092\n",
            "Epsilon: 0.08\tTest Accuracy = 112 / 10000 = 0.0112\n",
            "Epsilon: 0.09\tTest Accuracy = 137 / 10000 = 0.0137\n",
            "Epsilon: 0.1\tTest Accuracy = 155 / 10000 = 0.0155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bati9vmognj5"
      },
      "source": [
        "### Plots showing the Accuracy vs Epsilon Plots "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SqPHEFE6USM",
        "outputId": "4424cfdc-0299-4a68-e8ab-7e719beb3702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Plot of Accuracy vs Epsilon with 0.01 step size \n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(epsilons_net, accuracies_net, \"*-\")\n",
        "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
        "plt.xticks(np.arange(0, .1, step=0.01))\n",
        "plt.title(\"0.01 step\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# Plot of Accuracy vs Epsilon with 0.02 step size \n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(epsilons_net2, accuracies_net2, \"*-\")\n",
        "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
        "plt.xticks(np.arange(0, .2, step=0.02))\n",
        "plt.title(\"0.02 step\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# Plot of Accuracy vs Epsilon with 0.05 step size \n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(epsilons_net3, accuracies_net3, \"*-\")\n",
        "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
        "plt.xticks(np.arange(0, .5, step=0.05))\n",
        "plt.title(\"0.05 step\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmpnl4KA0M8vBQWlmloOD0swsh/8P7vfjAfliDuwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxddX3/8dd79snMZGVmhCwkkBsx\n7O0YsK2KWyUupKgo0Vqx/or+FGu1VrEgtfxof5W6VH5SC21dqUBqq01r/KGiVn8KmEE2AyYMIWQB\nySRkX2b9/P64Z8LNMDP3znLunZn7fj4e9zFn+d7z/dyZ8Oac873nHEUEZmY2vIpSF2BmNtk5KM3M\n8nBQmpnl4aA0M8vDQWlmloeD0swsDwelmVkeDkorKklzJX1T0iFJT0h66whtJemTknYnr09KUrJu\nmaT/kNQp6RlJd0h6/hjquUDS9vF8Jpv+HJRWbDcC3UAr8DbgC5JOH6bt5cDvAWcDZwGvB96drJsN\nrAWen2zr58B/pFe2lTMHpRWNpAbgjcDHI+JgRPw/smH39mHe8g7g0xGxPSJ2AJ8GLgOIiJ9HxD9H\nxDMR0QN8Fni+pHnD9P0aSQ9LOiBph6QPJ/V8BzhJ0sHkdZKkCklXSnos2ZNdI2lusp3FkkLS5ZKe\nlPSUpA9P4K/JJiEHpRXTMqA3IjblLHsAGG6P8vRkfSFtXwL8OiJ2D7P+n4F3R0QTcAbwg4g4BKwE\nnoyIxuT1JPB+snuyLwVOAvaQ3RPO9TIgA/wu8FFJrxymX5sGHJRWTI3A/kHL9gFNI7TfN6ht48B5\nygGSFpANsg+N0HcPsFzSzIjYExG/GKHte4Crkj3ZLuATwJskVeW0+cuIOBQRDwFfAlaPsD2b4hyU\nVkwHgZmDls0EDhTYfiZwMHLu5CKpGfgu8PcRcesIfb8ReA3whKT/lvSiEdqeDHxT0l5Je4FHgD6y\n50IHbMuZfoLsnqdNUw5KK6ZNQJWkTM6ys4ENw7TfkKwfsq2kOWRDcm1E/NVIHUfE+ohYBbQA3wLW\nDKwaovk2YGVEzM551SXnSQcszJleBDw5Uv82tTkorWiSc4L/DlwrqUHSbwOrgK8N85avAh+SNF/S\nScCfAl8GkDQTuAP4aURcOVK/kmokvU3SrGTgZz/Qn6x+GpgnaVbOW/4B+CtJJyfvb5a0atBmPy5p\nRjJi/07g9kJ+BzY1OSit2N4L1AM7gVuB/xkRGwAkvVjSwZy2NwH/CTwE/BL4drIM4GLghcA7c0as\nD0paNEy/bwe2SNpP9hzk2wAi4ldJHZuTQ+2TgM+RHY3/rqQDwN3AeYO2999AB3An8KmI+O7Yfh02\nFcg37jUrnKTFwONAdUT0lrYaKxbvUZqZ5ZFaUEr6oqSdkn45zHpJukFSh6QHJf1GWrWYmY1HmnuU\nXwYuHGH9SrJf2M2QvVTtCynWYjYhImJLRMiH3eUltaCMiB8Dz4zQZBXw1ci6G5gt6cS06jEzG6tS\nnqOcz/Ff2t2eLDMzm1Sq8jcpPUmXkz08p6Gh4TdPO+20EldkZtPNvffeuysimodaV8qg3MHxVzcs\nSJY9R0TcDNwM0NbWFu3t7elXZ2ZlRdITw60r5aH3WuAPktHv84F9EfFUCesxMxtSanuUkm4FLgBO\nSO4g/RdANUBE/AOwjuxNCjqAw2QvAzMzm3RSC8qIGPG2U8kdYN6XVv9mZhPFV+aYmeXhoDQzy8NB\naWaWh4PSzCwPB6WZWR4OSjOzPByUZmZ5OCjNzPJwUJqZ5eGgNDPLw0FpZpaHg9LMLA8HpZlZHg5K\nM7M8HJRmZnk4KM3M8nBQmpnl4aA0M8sj1aCUdKGkjZI6JF05xPqTJd0p6UFJP5K0IM16zMzGIrWg\nlFQJ3AisBJYDqyUtH9TsU8BXI+Is4Frgf6dVj5nZWKW5R7kC6IiIzRHRDdwGrBrUZjnwg2T6h0Os\nNzMruTSDcj6wLWd+e7Is1wPAG5Lpi4EmSfNSrMnMbNRKPZjzYeClku4DXgrsAPoGN5J0uaR2Se2d\nnZ3FrtHMylyaQbkDWJgzvyBZdkxEPBkRb4iIc4GrkmV7B28oIm6OiLaIaGtubk6xZDOz50ozKNcD\nGUlLJNUAlwJrcxtIOkHSQA0fA76YYj1mZmOSWlBGRC9wBXAH8AiwJiI2SLpW0kVJswuAjZI2Aa3A\nX6VVj5nZWCkiSl3DqLS1tUV7e3upyzCzaUbSvRHRNtS6Ug/mmJlNeg5KM7M8HJRmZnk4KM3M8nBQ\nmpnl4aA0M8vDQWlmloeD0swsDwelmVkeDkozszwclGZmeTgozczycFCameXhoDQzy8NBaWaWh4PS\nzCwPB6WZWR4OSjOzPByUZmZ5pBqUki6UtFFSh6Qrh1i/SNIPJd0n6UFJr0mzHjOzsUgtKCVVAjcC\nK4HlwGpJywc1u5rs0xnPJfs4279Pqx4zs7FKc49yBdAREZsjohu4DVg1qE0AM5PpWcCTKdZjZjYm\naQblfGBbzvz2ZFmuTwC/L2k7sA54/1AbknS5pHZJ7Z2dnWnUamY2rFIP5qwGvhwRC4DXAF+T9Jya\nIuLmiGiLiLbm5uaiF2lm5S3NoNwBLMyZX5Asy/UuYA1ARNwF1AEnpFiTmdmopRmU64GMpCWSasgO\n1qwd1GYr8AoASS8gG5Q+tjazSSW1oIyIXuAK4A7gEbKj2xskXSvpoqTZnwJ/JOkB4FbgsoiIiaxj\n5/6jvPmmu9h54OhEbtbMykhVmhuPiHVkB2lyl12TM/0w8Ntp1nDDnY+yfssz3PD9R7nu4jPT7MrM\npqlUg7KUnn/1d+jq7T82f8s9W7nlnq3UVlWw8bqVJazMzKaaUo96p+YnH3kZrz/rxGPzddUVrDrn\nJH7y0ZeVsCozm4qmbVC2zKxjZn01ABWCrt5+mmqraGmqK3FlZjbVTNtDb4BdB7tYNLee3v7g5ae1\n0ukBHTMbg2kdlDe9vY3PfG8Tn//Bo1z92hdQV11Z6pLMbAqatofeAzItjfQHbO48VOpSzGyKmv5B\n2doIwKM7D5S4EjObqqZ9UC45oYHKCtGx82CpSzGzKWraB2VtVSUnz5vBo087KM1sbKZ9UEL2POUm\nH3qb2RiVSVA28cTuw3T19pW6FDObgsojKFsb6esPtuw6XOpSzGwKKo+gbGkCPPJtZmNTFkF5SnMD\nFcIDOmY2JmURlHXVlSyaO8N7lGY2JmURlABLW5q8R2lmY1I2QbmstZHHdx2ip68/f2MzsxxlE5SZ\n1kZ6+4MndvuabzMbnVSDUtKFkjZK6pB05RDrPyvp/uS1SdLetGoZGPne5MNvMxul1G6zJqkSuBF4\nFbAdWC9pbfKcHAAi4oM57d8PnJtWPac2N6KBkW8/OsfMRiHNPcoVQEdEbI6IbuA2YNUI7VeTfRJj\nKuprKlkwp94j32Y2amkG5XxgW8789mTZc0g6GVgC/CDFeljW0uS7CJnZqE2WwZxLgW9ExJAXY0u6\nXFK7pPbOzs4xd7K0tZHNnYfo9ci3mY1CmkG5A1iYM78gWTaUSxnhsDsibo6Itohoa25uHnNBmZYm\nuvv6eeIZX/NtZoVLMyjXAxlJSyTVkA3DtYMbSToNmAPclWItQPZ2a+BLGc1sdFILyojoBa4A7gAe\nAdZExAZJ10q6KKfppcBtERFp1TJgaRKUHR7QMbNRSPUpjBGxDlg3aNk1g+Y/kWYNuRpqq5g/u55H\nPaBjZqMwWQZziibT2uhDbzMblfILypZGHus8SF9/6kf6ZjZNlGFQNtHV2882j3ybWYHKLyiPPefb\nh99mVpiyC8qBkW9fymhmhSq7oGyqq+bEWXUe0DGzgpVdUEJ2r9J7lGZWqLIMykxyc4x+j3ybWQHK\nMiiXtTZytKefHXuPlLoUM5sCyjIonx359uG3meVXlkG5tNmPhTCzwpVlUM6aUU1LU61Hvs2sIGUZ\nlADLWpt8FyEzK0jZBmX2K0IHKcLd3cxsiivboMy0NnK4u48n9x0tdSlmNsmVb1Aee863D7/NbGRl\nHJTJ3c49oGNmeZRtUM5pqOGExlp/l9LM8ko1KCVdKGmjpA5JVw7T5s2SHpa0QdLX06xnsEwyoGNm\nNpLUglJSJXAjsBJYDqyWtHxQmwzwMeC3I+J04E/SqmcomdZGOp72yLeZjSzNPcoVQEdEbI6IbuA2\nYNWgNn8E3BgRewAiYmeK9TxHpqWRA129/Hq/R77NbHhpBuV8YFvO/PZkWa5lwDJJP5V0t6QLU6zn\nOZYmI9++QsfMRlLqwZwqIANcAKwG/lHS7MGNJF0uqV1Se2dn54R1vsyPhTCzAqQZlDuAhTnzC5Jl\nubYDayOiJyIeBzaRDc7jRMTNEdEWEW3Nzc0TVuC8xlrmNtT4UkYzG1GaQbkeyEhaIqkGuBRYO6jN\nt8juTSLpBLKH4ptTrOk5lrY0+i5CZjai1IIyInqBK4A7gEeANRGxQdK1ki5Kmt0B7Jb0MPBD4M8i\nYndaNQ0l09LIo08f8Mi3mQ2rKs2NR8Q6YN2gZdfkTAfwoeRVEpmWRvYf7aXzQBctM+tKVYaZTWKl\nHswpuWWtyci3B3TMbBh5g1LS+yXNKUYxpbB0YOTbN8cws2EUskfZCqyXtCa5JFFpF1VMzY21zKqv\nZpP3KM1sGHmDMiKuJvuVnX8GLgMelfTXkk5NubaikESmpdF3ETKzYRV0jjIZdPl18uoF5gDfkHR9\nirUVTaa1iU07PfJtZkMr5BzlByTdC1wP/BQ4MyL+J/CbwBtTrq8oMi2N7D3cw+5D3aUuxcwmoUK+\nHjQXeENEPJG7MCL6Jb0unbKKa+A535uePsAJjbUlrsbMJptCDr2/AzwzMCNppqTzACLikbQKK6aB\nx0J0eEDHzIZQSFB+AchNkIPJsmmjdWYtTbVVvouQmQ2pkKBU5IxyREQ/KV/RU2ySyLQ2+rEQZjak\nQoJys6Q/llSdvD5AkW9cUQyZliYfepvZkAoJyvcAv0X2FmnbgfOAy9MsqhQyrY3sOtjNMx75NrNB\n8h5CJ49nuLQItZTU0pZnL2U875R5Ja7GzCaTvEEpqQ54F3A6cOz2OhHxhynWVXSZnJtjOCjNLFch\nh95fA54HvBr4b7J3Kp92ox4nzaqjoabS5ynN7DkKCcqlEfFx4FBEfAV4LdnzlNOKJJa2Nnnk28ye\no5Cg7El+7pV0BjALaEmvpNLJ+LEQZjaEQoLy5uR+lFeTfebNw8AnU62qRDItjXQe6GLvYY98m9mz\nRgxKSRXA/ojYExE/johTIqIlIm4qZOPJ/Ss3SuqQdOUQ6y+T1Cnp/uT1P8b4OSbEwN3OfZ7SzHKN\nGJTJVTgfGcuGJVUCNwIrgeXAaknLh2h6e0Sck7z+aSx9TZRjXxFyUJpZjkIOvb8v6cOSFkqaO/Aq\n4H0rgI6I2BwR3cBtwKpxVZuy+bPrqa+uZJMfC2FmOQq5Zvstyc/35SwL4JQ875sPbMuZH7iqZ7A3\nSnoJsAn4YERsG6JNUVRUiKUtjT70NrPjFHJlzpIU+/9P4NaI6JL0buArwMsHN5J0Ocllk4sWLUqx\nnOyAzs8eK+qjxc1skivkypw/GGp5RHw1z1t3AAtz5hcky3K3kZtI/0T2LupD9XUzcDNAW1tbqs9r\nyLQ28e/37WD/0R5m1lWn2ZWZTRGFnKN8Yc7rxcAngIsKeN96ICNpiaQasteLr81tIOnEnNmLgJLf\nCDiTDOj48NvMBhRy6P3+3HlJs8kOzOR7X6+kK4A7gErgixGxQdK1QHtErAX+WNJFZB9Y9gzZpzyW\nVCbnOd+/sWjaPs7czEZhLDfgPQQUdN4yItYB6wYtuyZn+mPAx8ZQQ2oWzJlBbVWF73ZuZscUco7y\nP8mOckP2UH05sCbNokqpskKc2tzo71Ka2TGF7FF+Kme6F3giIranVM+ksKy1kfVb9pS6DDObJAoZ\nzNkK3BMR/x0RPwV2S1qcalUllmltYsfeIxzs6i11KWY2CRQSlP8K9OfM9yXLpq2lHvk2sxyFBGVV\ncgkiAMl0TXollV4m57EQZmaFBGVn8hUeACStAnalV1LpLZo7g5qqCu9RmhlQ2GDOe4B/kfT5ZH47\nMOTVOtNFVWUFp5zQ4JFvMwMK+8L5Y8D5khqT+bJIj0xrE/dt9ci3mRVw6C3pryXNjoiDEXFQ0hxJ\n1xWjuFLKtDSyfc8RDnd75Nus3BVyjnJlROwdmImIPcBr0itpchgY0Hls56ESV2JmpVZIUFZKqh2Y\nkVQP1I7Qflp49jnfHvk2K3eFDOb8C3CnpC8BInvjiq+kWdRkcPK8GVRXygM6ZlbQYM4nJT0AvJLs\nNd93ACenXVipVVdWsOSEBn+X0swKOvQGeJpsSF5C9g7kJb9vZDFkWpq8R2lmw+9RSloGrE5eu4Db\nAUXEy4pUW8ktbWlk3S+f4mhPH3XVlaUux8xKZKQ9yl+R3Xt8XUT8TkT8H7LXeZeNZa1NRMBjnd6r\nNCtnIwXlG4CngB9K+kdJryA7mFM2Bu527ksZzcrbsEEZEd+KiEuB04AfAn8CtEj6gqTfLVaBpbR4\nXgOVFfJzvs3KXN7BnIg4FBFfj4jXk32S4n3ARwvZuKQLJW2U1CHpyhHavVFSSGoruPIiqKmqYPG8\nGX4shFmZK3TUG8helRMRN0fEK/K1lVQJ3AisJPv4iNWSlg/Rrgn4AHDPaGoplkxLkw+9zcrcqIJy\nlFYAHRGxObmH5W3AqiHa/S/gk8DRFGsZs2WtjWzZfYiu3rIaxzKzHGkG5XxgW8789mTZMZJ+A1gY\nEd9OsY5xWdraRH/A5k5f821WrtIMyhFJqgA+A/xpAW0vl9Quqb2zszP94nIcu9u5D7/NylaaQbkD\nWJgzvyBZNqAJOAP4kaQtwPnA2qEGdJLzom0R0dbc3Jxiyc+15IQGKgQdHvk2K1tpBuV6ICNpiaQa\n4FJg7cDKiNgXESdExOKIWAzcDVwUEe0p1jRqddWVLJ7nu52blbPUgjIieoEryN5E4xFgTURskHRt\n7jN4poKlLY0OSrMyVsht1sYsItYB6wYtu2aYthekWct4ZFob+cGvdtLd209NVclO65pZifi/+gJk\nWpro7Q+27PbIt1k5clAWYOmx53z78NusHDkoC7C0pRHJj4UwK1cOygLUVVeyaO4MD+iYlSkHZYEy\nLY1+LIRZmXJQFmhpSxOP7zpET19/qUsxsyJzUBYo09JIT1/wxO7DpS7FzIrMQVmgZclzvjs8oGNW\ndhyUBTq1pQGATf6KkFnZcVAWaEZNFQvm1Hvk26wMOShHwSPfZuXJQTkKy1qb2LzrEL0e+TYrKw7K\nUVja0kh3bz/b9hwpdSlmVkQOylHIJCPffnytWXlxUI7CwM0x/FRGs/LioByFxtoqTppV5wEdszLj\noBylTGuTvyJkVmYclKOUaWmkY+dB+vqj1KWYWZGkGpSSLpS0UVKHpCuHWP8eSQ9Jul/S/5O0PM16\nJkKmtZGu3n627/E132blIrWglFQJ3AisBJYDq4cIwq9HxJkRcQ5wPdnnfE9qS1uyI9++27lZ+Uhz\nj3IF0BERmyOiG7gNWJXbICL258w2AJP+ePbYYyF8ntKsbKT5FMb5wLac+e3AeYMbSXof8CGgBnh5\nivVMiFn11TxvZp0fC2FWRko+mBMRN0bEqcBHgauHaiPpckntkto7OzuLW+AQMq2NPvQ2KyNpBuUO\nYGHO/IJk2XBuA35vqBURcXNEtEVEW3Nz8wSWODZLk5Hvfo98m5WFNINyPZCRtERSDXApsDa3gaRM\nzuxrgUdTrGfCZFqaONLTx469vubbrBykdo4yInolXQHcAVQCX4yIDZKuBdojYi1whaRXAj3AHuAd\nadUzkTKtz17KuHDujBJXY2ZpS3Mwh4hYB6wbtOyanOkPpNl/WjLHRr4P8LLTWkpcjZmlreSDOVPR\n7Bk1NDfV+rEQZmXCQTlGmZZGf5fSrEw4KMco09JIx9MHiPDIt9l056Aco0xrE4e6+3hq39FSl2Jm\nKXNQjlHGlzKalQ0H5RgNPBbCN/E1m/4clGM0t6GGeQ01vpTRrAw4KMdhaUujb45hVgYclOOwLHks\nhEe+zaY3B+U4ZFobOXC0l6f3d5W6FDNLkYNyHJbmXMpoZtOXg3IcMn4shFlZcFCOwwmNNcyeUe3v\nUppNcw7KcZDEspYmOnzobTatOSjHaWlrI5ue9si32XTmoBynTEsj+4700HnQI99m05WDcpwGBnQ6\nPKBjNm05KMdpWfJYiI998yF2HvCdhMymIwflODU31VJdKZ7YfZgbvj8lno1mZqOU6jNzJF0IfI7s\nw8X+KSL+ZtD6DwH/A+gFOoE/jIgn0qxpIj3/6u/Q1dt/bP6We7Zyyz1bqa2qYON1K0tYmZlNpNT2\nKCVVAjcCK4HlwGpJywc1uw9oi4izgG8A16dVTxp+8pGXcdE5J1FZIQBqqipYdc5J/OSjLytxZWY2\nkdI89F4BdETE5ojoBm4DVuU2iIgfRsThZPZuYEGK9Uy4lpl1NNVW0Z98Nai7t5/aqgpamupKXJmZ\nTaQ0g3I+sC1nfnuybDjvAr4z1ApJl0tql9Te2dk5gSWO366DXbztvJP59CVnA/CTR3eVuCIzm2ip\nnqMslKTfB9qAlw61PiJuBm4GaGtrm1Tf7L7p7W3HpnfsPcJnvreJb963nYvPnVI7x2Y2gjT3KHcA\nC3PmFyTLjiPplcBVwEURMaW/tf2+ly3lhYvn8PFvbWDr7sP532BmU0KaQbkeyEhaIqkGuBRYm9tA\n0rnATWRDcmeKtRRFZYX47FvOQYIP3H4fvX39+d9kZpNeakEZEb3AFcAdwCPAmojYIOlaSRclzf4W\naAT+VdL9ktYOs7kpY8GcGfz1xWdy39a93HCnv1dpNh2keo4yItYB6wYtuyZn+pVp9l8qrz/7JH60\nsZPP/7CD38k0s2LJ3FKXZGbj4CtzUvKXq05n4dwZfPD2+9l3pKfU5ZjZODgoU9JYW8XnLj2Xp/cf\n5apvPuTbsJlNYQ7KFJ2zcDYffNUy/uvBp/i3XzxnwN/MpggHZcre89JTOW/JXP7iP37Jll2HSl2O\nmY2BgzJlA18Zqqqs4AO33UePvzJkNuU4KIvgpNn1/O83nMkD2/fxd9/fVOpyzGyUHJRF8pozT+Qt\nbQv5+x89xt2bd5e6HDMbBQdlEV3z+uUsntfAB2+/n72Hu0tdjpkVyEFZRA21VXzu0nPoPNDFn/sr\nQ2ZThoOyyM5aMJsPv/r5rHvo16xp35b/DWZWcg7KErj8xafwW6fO4xNrH2Zzp5/eaDbZOShLoKJC\nfObN51BbXcEHbruf7l5/ZchsMnNQlsjzZtXxN284i4d27OPT39tY6nLMbAQOyhK68IznsXrFIm7+\n8WZ+1uFHSJhNVg7KEvv4617AKSc08ME197PnkL8yZDYZOShLbEZN9i5Dzxzq5qP/9qC/MmQ2CTko\nJ4Ez5s/iI68+je8+/DS3/txfGTKbbByUk8S7fmcJL86cwLX/tYGOnf7KkNlkkmpQSrpQ0kZJHZKu\nHGL9SyT9QlKvpDelWctkV1EhPn3J2cyoqeKPb72Prt6+UpdkZonUglJSJXAjsBJYDqyWtHxQs63A\nZcDX06pjKmmZWccn33gWDz+1n0/d4a8MmU0Wae5RrgA6ImJzRHQDtwGrchtExJaIeBDwN64Tr1re\nytvPP5l//Mnj/OTRzlKXY2akG5TzgdyRie3JMsvjqte+gExLIx9a8wC7D3aVuhyzsjclBnMkXS6p\nXVJ7Z+f038uqq67khtXnsu9wj78yZDYJpBmUO4CFOfMLkmWjFhE3R0RbRLQ1NzdPSHGT3QtOnMmV\nK0/j+4/s5Ja7nyh1OWZlLc2gXA9kJC2RVANcCqxNsb9p552/vZiXLmvmum8/wqanD5S6HLOylVpQ\nRkQvcAVwB/AIsCYiNki6VtJFAJJeKGk7cAlwk6QNadUzFUniU5ecTWNtFe+95V7e9IWfsfPA0VKX\nZVZ2Uj1HGRHrImJZRJwaEX+VLLsmItYm0+sjYkFENETEvIg4Pc16pqLmplo+dcnZdHQeov2JPdzw\n/UdLXZLZpLZz/1HefNNdE7pTMSUGc8rZ86/+Du/88vpj87fcs5XFV36bpX++js4DHhG3qSWNEBvs\nhjsfZf2WZyZ0p0JTbUS1ra0t2tvbS11G0ezcf5Tr1j3Cdzf8mqM9/VQIBPQlf7ZMSyPnnzKPF506\nj/OWzGVeY21J6zUbydXffIh/+flW3rZiEdddfOax5b19/Rzp6eNoTz9He/qSVz9He/s40p3M9/Zz\ntLuPo73Z+SPd/cemj/b0cfv6bfQPEWe1VRVsvG5l3tok3RsRbUOtqxr7R7ZiaJlZR1NtFV29/dRW\nVdDd18+lL1zIJW0LuWvzbu7e/Az/9ovtfC0ZGX9+axPnnzKXF506jxVL5jG3oabEn8Cmip37j3LF\nrffx+beeS0tTXcHv6+nrZ9+RHvYe7mHfkR72Helm7+Hs/N4jPew/0sNX79pyXIjdcs9WbrlnKwBV\nFaJ3qIQrQHWlqKuqpK6mkufNqmP/kV4OdfUSZAPywjOex1WvfcGYtp3LQTkF7DrYxdvOO5m3rljE\n13++lc4DRzl30RzOXTSH916Q/Yf64PZ93L15N3dv3s2a9u185a5scJ72vCbOP2Ve8prL7BkOzqlm\nrAE2Gv39wae/u4n1W57hL9c+zO+ff/KxwNt3JBt42emcZcnPg129I257Zl0VJ86q52BXLweO9tAf\nUClYMHcG558yl3kNtdRVV1JXXUF9dSW11ZXUVVdSnyzLna6tqqS+Jru+rqqCqsrjzx5e9c2H+PrP\nt1Jbmd2paKqtmpDfmQ+9p6Hu3n4e3L6Xuzfv5q7Nu2nfsoeu3n4kOO15M3lREprnLZnHrBnVx723\nGP9RTifF+H3lHq5eu+oMDvf0cbirl8PdfRzq7uVIdx+Huvs40t3Loa4+DncPrEuWdWcPXw919XKk\nJ/vzcHdf8upl18H8N4yuqhCzZ1Qzq76a2TNqmF1fzayB+foaZs+oPm59dnk1M+urqawQ8GyI1SQh\nNvjweyK8+2vtNDfVHbdTcdPbhzyafo6RDr0dlGWgq7ePB7Zl9zjvemw3927dQ3cSnMtPHAjOeaw4\nZS7Xf+dXQ55DmkjFCuNihnj/+jYAAApESURBVNhb2hbykQtPy547yz3HNmh6YF1Xb3/Oubdnz7d1\nJW2P9PTxiyf2MN7/OuurK2moze6FNdRUDfpZSX1NFSJof2IPmzsP0dsfVFeKFYvn8p4LTuWU5kZm\n11czo6YSSeOqZTwhVgwOSjvO0Z4+Hti2l7uS4Lxv6166+4a+L0llhXjfBadSV5M9/KmvfvbQZ2B6\n8CFSfU0ldVWVVFQM/R/WcCf0J9pw/XT19nG4q4+DXb0cSvbCDnVlz20dSva8sstz1nX3crAruyd3\nsKuXX/16/BcAVIicw8pKapNDz4HD0ArgsV2HeHrfUfoi+7dY2tLAhaefSHNTbTYAq6toqK1kRk0l\nM2qqjvtZXz3832CwYuztTXYOShvR0Z4+fvCrnfzd9zfRsfPgsZPuNZWiQuLoGB+nW1tVcSxI66sr\neXzXoSH3kCoEL1n27KWpg/9J5s6O9O91YNVPH9v1nG0MqK4UPX2F/ZuvEDTUVtFYW0VDbRUNNZU0\n1FYxo6aKqgr41a8PsG3PEfr6g6oK8YITm7jo7JNobqo77pxb3aBzbrXJdHWl8u6lFSvAJvveXjF4\n1NtGVFddyWvOPJGfduzi0Z0Hj42uv7ltIdddfCYRcexQceDQ8djP7uxh4pGePo4m649rc2xZP/Nn\n1/OrX+9n16FuIrJfc5pVX82Js+ue+2C1QQGi4VcNWifOPGkW2/YcZu+RHiKygTd/dj3nnzKPE5pq\naazN7nENhOCMmsrk50AoZtfVVlWMGGTHBg6S39fZC2bzRy85dUx/g+EMNZCXhtxQvO73zkilj6nM\nQWnHDPcfpaRje0VzxtnH4HB53VknprKHNLifly5rnvB+ihFiDrDJwUFpxxTjP8pi7SE5xGwi+Ryl\nmRkjn6P0td5mZnk4KM3M8nBQmpnl4aA0M8vDQWlmloeD0swsj1SDUtKFkjZK6pB05RDrayXdnqy/\nR9LiNOsxMxuL1IJSUiVwI7ASWA6slrR8ULN3AXsiYinwWeCTadVjZjZWae5RrgA6ImJzRHQDtwGr\nBrVZBXwlmf4G8AqN915OZmYTLM2gnA9sy5nfniwbsk3yeNt9wLwUazIzG7Upca23pMuBy5PZg5I2\njnITJwC7JraqadtHsfrxZ5l8fRSrn2J9ltE6ebgVaQblDmBhzvyCZNlQbbZLqgJmAbsHbygibgZu\nHmshktqHu4ZzokyXPorVjz/L5OujWP0U67NMpDQPvdcDGUlLJNUAlwJrB7VZC7wjmX4T8IOYanfp\nMLNpL7U9yojolXQFcAdQCXwxIjZIuhZoj4i1wD8DX5PUATxDNkzNzCaVVM9RRsQ6YN2gZdfkTB8F\nLkmzhsSYD9vLsI9i9ePPMvn6KFY/xfosE2bK3Y/SzKzYfAmjmVkeUzoox3OJpKSPJcs3Snp1Gv1I\nepWkeyU9lPx8eRqfJVm/SNJBSR9Oow9JZ0m6S9KG5PMM+6Dscfy+qiV9Jdn+I5I+No4+XiLpF5J6\nJb1p0Lp3SHo0eb1j8HvH24ekc3J+Vw9KestwfYz3syTrZ0raLunzafSR/Nv6bvI3eXjwv70J7Of6\n5Hf2iKQbpEl08UlETMkX2QGix4BTgBrgAWD5oDbvBf4hmb4UuD2ZXp60rwWWJNupTKGfc4GTkukz\ngB0T3UfO+m8A/wp8OIXPUQU8CJydzM9L6ff1VuC2ZHoGsAVYPMY+FgNnAV8F3pSzfC6wOfk5J5me\nM8F9LAMyyfRJwFPA7HH8vobsJ2f954CvA59Pow/gR8CrkulGYMZE9wP8FvDTZBuVwF3ABcXIkkJe\nU3mPcjyXSK4i+x9kV0Q8DnQk25vQfiLivoh4Mlm+AaiXVDvBnwVJvwc8nvQxnPH08bvAgxHxAEBE\n7I6IvhT6CaBB2e/U1gPdwP6x9BERWyLiQWDwQ8lfDXwvIp6JiD3A94ALJ7KPiNgUEY8m008CO4Fm\nhjaez4Kk3wRage8Os/1x9aHs/RmqIuJ7SbuDEXE4hc8SQB3ZgK0FqoGnR/hMRTWVg3I8l0gW8t6J\n6CfXG4FfRETXRPYhqRH4KPCXw9Q/EZ9jGRCS7kgOmz6SUj/fAA6R3QPbCnwqIp4ZYx/jqW+8fRwj\naQXZ//gfG2c9Q227Avg0MOzplvH2QfZvv1fSv0u6T9LfKnvDmwntJyLuAn5I9m//FHBHRDxSYI2p\nm8pBOWVIOp3snZHencLmPwF8NiIOprDtAVXA7wBvS35eLOkVKfSzAugje7i6BPhTSaek0E9RSDoR\n+Brwzoh4zt7gBHgvsC4itqew7QFVwIvJhvELyR5WXzbRnUhaCryA7BV884GXS3rxRPczVlM5KEdz\niSQ6/hLJQt47Ef0gaQHwTeAPImK4vYrx9HEecL2kLcCfAH+u7Bf9J7KP7cCPI2JXcti1DviNFD7L\nW4H/GxE9EbGT7DmroS51G83fb6zvHU8fSJoJfBu4KiLunoB6hvIi4Irkb/8p4A8k/c0E97EduD85\nnO4FvsX4/vbDuRi4Ozm0Pwh8h+znmxxKfZJ0rC+y/6fbTHbPY+DE8emD2ryP4wcN1iTTp3P8YM5m\nhh+cGE8/s5P2b0jrswxq8wmGH8wZz+eYA/yC7ABLFfB94LUp9PNR4EvJdAPwMHDWWPrIaftlnjuY\n83jymeYk03MnuI8a4E7gTybi3/Fw/QxadxnDD+aM57NUJu2bk/kvAe9LoZ+3JP+uqsien7wTeP1o\nMiHNV8kLGFfx8BpgE9nzP1cly64FLkqm68iOBHcAPwdOyXnvVcn7NgIr0+gHuJrsObf7c14tE/1Z\ncrbxCYYJygn4ff0+2cGiXwLXp/T7akyWbyAbkn82jj5eSHZv6BDZvdUNOe/9w6TvDrKHxRPaR/K7\n6hn0dz8njc+Ss43LGCYoJ+D39Sqy33p4iGzA1aTwO6sEbgIeSf72nyl1vuS+fGWOmVkeU/kcpZlZ\nUTgozczycFCameXhoDQzy8NBaWaWh4PSJi1JfZLuz3k95240BWyjTdINyfRlI91hx2w4U+IpjFa2\njkTEOePZQES0A+0TVI+VKe9R2pQjaUty78KHJP08uU4YSZdI+qWkByT9OFl2gaT/GmIbiyX9ILlf\n5J2SFiXLv5zcC/FnkjYPdf9HKz8OSpvM6gcdeufeAHdfRJwJfB74u2TZNcCrI+Js4KI82/4/wFci\n4izgX4AbctadSPbmH68Dhrp22sqMD71tMhvp0PvWnJ+fTaZ/CnxZ0hrg3/Ns+0XAG5LprwHX56z7\nVmTv9vOwpNbRl23TjfcobaqKwdMR8R6y19cvBO6VNPieoIXKvWfo5HkcgZWMg9Kmqrfk/LwLQNKp\nEXFPZB+J3Mnxt/wa7Gc8+xz5twE/SatQm/p86G2TWb2k+3Pm/29EDHxFaI6kB8nu/a1Olv2tpAzZ\nvcA7yd7m66XDbPv9wJck/RnZUH3nhFdv04bvHmRTTnKj2raI2FXqWqw8+NDbzCwP71GameXhPUoz\nszwclGZmeTgozczycFCameXhoDQzy8NBaWaWx/8H60eqHrijII0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7mKvE83NbZC"
      },
      "source": [
        "Changing the epsilon value beyond a certain point does not seem to further deteriorate the rate of misclassification in this case around 0.05. This pertubation is small especially compared with the epsillon required in a single channel greyscale image like FashionMNIST. Models that classify three channel images are less robust to adversarial attacks it seems. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY0kMDLduWU_",
        "outputId": "2e2c7876-4a5f-4ebb-c671-1dcd45c6576a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# Using matplotlib to plot the degradation in accuracy for three different architectures \n",
        "plt.plot( epsilons_net, accuracies_net, color='skyblue', linewidth=2, label=\"Net Architecture\")\n",
        "plt.plot( epsilons_lenet, accuracies_lenet, color='olive', linewidth=2, label=\"LeNet Architecture\")\n",
        "plt.plot( epsilons_resnet, accuracies_resnet, color='red',linewidth=2, label=\"ResNet Architecture\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f31502038d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhWZy3NVN5oP"
      },
      "source": [
        "The three architectures and there response to adversarial attacks. \n",
        "\n",
        "The best performing architecture seems to be the least robust. Why this could be? It could be overfitting. \n",
        "\n",
        "LeNet performed poorly on the training set it is not surprising that a larger pertubation is required to fool this model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq7-RobVQEm6"
      },
      "source": [
        "Conclusion and summary \n",
        "\n",
        "Three Neural Networks were trained then attacked using the fast gradient sign method there robustness varied.\n",
        "\n",
        "To protect our model we could train it using some adversarial examples, this however would reduce the accuracy of our training data i.e it would be a worse classifier and for that reason it would be harder to attack.  There are other techniques that could be used however there is no simple way to combat adversarial examples what is required is an adaptive method which does not exist.\n",
        "\n",
        "Further Reading \n",
        "\n",
        "- Adversarial training can result in regularization even further regularization than dropout. \n",
        "\n",
        "- Models that are easy to optimize are easy to perturb.\n",
        "\n",
        "- Ensembles are not resistant to adversarial examples.\n",
        "\n",
        "\n"
      ]
    }
  ]
}