{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Main_Titanic.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ruDf3I7I-cs"
      },
      "source": [
        "# Titanic Project -- Catherine Yijie(SHEN)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIH21v1UI-ct"
      },
      "source": [
        "# 0. Importing libraries & useful starting lines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kPUGjnvI-cv"
      },
      "source": [
        "Begin by importing libraries.\n",
        "* **Numpy**: This gives us the benefit of numpy arrays, this allows us the use of vectorised operations, this is faster than using loops. It is also the base for the other packages\n",
        "* **Matplotlib**: for plotting and visualisations\n",
        "* **Pandas** : This library is useful in machine learning, it enables the easy importation and manipulation of data; the pandas's dataframe is very easy and useful to work with, it also works well with other libraries becuase it gives the data some standard structure\n",
        "* **Seaborn**: This package is for plotting and statistics\n",
        "* **Math**: This package allows the use of some basic math functions\n",
        "* **Linalg**: The functions from linalg are useful since vectorised operations are used frequently "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsJR2cepI-cw"
      },
      "source": [
        "# Useful starting lines\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import math \n",
        "from numpy import linalg as la\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d15wGxjI-c1"
      },
      "source": [
        "# 1. Midterm - Titanic project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "772vlGA9I-c2"
      },
      "source": [
        "This project is a **binary classification problem**, where we have to **predict the likelihood** of passengers  surviving the Titanic accident based on some passenger attributes such as: **Name** , **Gender** , **Age** , **Number of siblings** , **Number of parents/children aboard** , **Class type** , **Fare**.\n",
        "\n",
        "Solving this problem, allows us to answer questions like: *What kind of people were more likely to survive Titanic?* ; *Did older people had better chance of surviving?* etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsCPADuoI-c3"
      },
      "source": [
        "## 1.1 Import the data \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhJm5uwrI-c3"
      },
      "source": [
        "The data was imported from a csv using the pandas library. The datatype was **pandas dataframe**, with dimension of **887 rows** (passengers) and **8 columns  (attributes)** including the headings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JYijyo0I-c4",
        "outputId": "8c58b0ef-6e28-4fa9-be0e-ecb0a2287b38"
      },
      "source": [
        "# Import the data using pandas library \n",
        "training_data = pd.read_csv('titanic.csv')\n",
        "type(training_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5h-fklAI-c9",
        "outputId": "0257c172-88d4-416c-cb88-6d76eff7dbcf"
      },
      "source": [
        "# Check the shape of the training data \n",
        "training_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(887, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQFK78w5I-dA",
        "outputId": "5cc6c95c-aadc-4c7f-f4c5-0bbc77336a55"
      },
      "source": [
        "# Check the columns of the data\n",
        "training_data.columns "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard',\n",
              "       'Parents/Children Aboard', 'Fare'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb9YotaXI-dE",
        "outputId": "d6f7f799-6c06-4726-a05c-6989ba1eed74"
      },
      "source": [
        "# See first 10 rows of the data and headings \n",
        "training_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Owen Harris Braund</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Miss. Laina Heikkinen</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. William Henry Allen</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. James Moran</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr. Timothy J McCarthy</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Master. Gosta Leonard Palsson</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Mrs. Oscar W (Elisabeth Vilhelmina Berg) Johnson</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.1333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Mrs. Nicholas (Adele Achem) Nasser</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass                                               Name  \\\n",
              "0         0       3                             Mr. Owen Harris Braund   \n",
              "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
              "2         1       3                              Miss. Laina Heikkinen   \n",
              "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
              "4         0       3                            Mr. William Henry Allen   \n",
              "5         0       3                                    Mr. James Moran   \n",
              "6         0       1                             Mr. Timothy J McCarthy   \n",
              "7         0       3                      Master. Gosta Leonard Palsson   \n",
              "8         1       3   Mrs. Oscar W (Elisabeth Vilhelmina Berg) Johnson   \n",
              "9         1       2                 Mrs. Nicholas (Adele Achem) Nasser   \n",
              "\n",
              "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
              "0    male  22.0                        1                        0   7.2500  \n",
              "1  female  38.0                        1                        0  71.2833  \n",
              "2  female  26.0                        0                        0   7.9250  \n",
              "3  female  35.0                        1                        0  53.1000  \n",
              "4    male  35.0                        0                        0   8.0500  \n",
              "5    male  27.0                        0                        0   8.4583  \n",
              "6    male  54.0                        0                        0  51.8625  \n",
              "7    male   2.0                        3                        1  21.0750  \n",
              "8  female  27.0                        0                        2  11.1333  \n",
              "9  female  14.0                        1                        0  30.0708  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTSaFpRDI-dI"
      },
      "source": [
        "Looking at the first 10 passenger , a general idea of the data can be realised, what they are, and what values they can take, it will be analysed in more detail in the next section:\n",
        "* **Survived** : **Binary label**, shows if the passenger has survived, it can take two values 0 and 1 (where 0 = die, 1=survived)\n",
        "* **Pclass** : Class the passanger travelled, where the values can be 1, 2, or 3. The  number means higher class.\n",
        "* **Name** : Passanger name (string)\n",
        "* **Sex** : Passanger Gender  (string)\n",
        "* **Age** : PassangerAge in years (continuous values) \n",
        "* **Siblings/Spouses Aboard** : Number of siblings or spouses aboard of the passenger (discrete  values)\n",
        "* **Parents/Children Aboard** : Number of parents or children aboard of the passenger (discrete  values)\n",
        "* **Fare** : Fare of the ticket (continuous values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWTfMIDqI-dJ"
      },
      "source": [
        "##  1.2 Data Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VrY8CN1I-dL"
      },
      "source": [
        "In machine learning much time is spent for the preparation of the data. Before we can use our model, the data must be formatted correctly. \n",
        "\n",
        "A prerequisite of this is to validate the data. This process  involves, checking for **missing values**, checking if all values are in he right data type, checking for duplicates and checking for **erroneous values** (**Age** includes a negative number)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN70zT4lI-dM",
        "outputId": "25c8f368-79bc-4f9a-a804-f322f81c5c27"
      },
      "source": [
        "# Check the data for missing values \n",
        "training_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 887 entries, 0 to 886\n",
            "Data columns (total 8 columns):\n",
            "Survived                   887 non-null int64\n",
            "Pclass                     887 non-null int64\n",
            "Name                       887 non-null object\n",
            "Sex                        887 non-null object\n",
            "Age                        887 non-null float64\n",
            "Siblings/Spouses Aboard    887 non-null int64\n",
            "Parents/Children Aboard    887 non-null int64\n",
            "Fare                       887 non-null float64\n",
            "dtypes: float64(2), int64(4), object(2)\n",
            "memory usage: 48.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sA-8sXZI-dR",
        "outputId": "9d8360f7-e880-4a60-ebb5-4715787c77a2"
      },
      "source": [
        "# Find the number of missing values  \n",
        "training_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived                   0\n",
              "Pclass                     0\n",
              "Name                       0\n",
              "Sex                        0\n",
              "Age                        0\n",
              "Siblings/Spouses Aboard    0\n",
              "Parents/Children Aboard    0\n",
              "Fare                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIhK9FgeI-dV"
      },
      "source": [
        "The dataset contains no missing values, if they are present there are different approaches to deal with this:\n",
        "\n",
        "* **Drop the missing values** with *training_data.dropna()*. This only suggested if the number of missing values is small.\n",
        "\n",
        "* Alternately **replace the missing values** with the mean using *.mean()* and *.fillna* functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6z1aoHaI-dW",
        "outputId": "03a78ecc-284b-4070-ec19-0ba571d68c89"
      },
      "source": [
        "# If we have missing values we can drop them \n",
        "# This only suggested if the number of missing values is small\n",
        "\n",
        "training_data.dropna().head()\n",
        "\n",
        "# Also we can replace them with the mean using the mean\n",
        "# We simply take the column heading and .mean()\n",
        "# We can use .fillna with the mean values when true "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Owen Harris Braund</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Miss. Laina Heikkinen</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. William Henry Allen</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass                                               Name  \\\n",
              "0         0       3                             Mr. Owen Harris Braund   \n",
              "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
              "2         1       3                              Miss. Laina Heikkinen   \n",
              "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
              "4         0       3                            Mr. William Henry Allen   \n",
              "\n",
              "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
              "0    male  22.0                        1                        0   7.2500  \n",
              "1  female  38.0                        1                        0  71.2833  \n",
              "2  female  26.0                        0                        0   7.9250  \n",
              "3  female  35.0                        1                        0  53.1000  \n",
              "4    male  35.0                        0                        0   8.0500  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsH20NC1I-da",
        "outputId": "1575a1ac-16e4-4352-d98c-ac7b6a3e1d63"
      },
      "source": [
        "# Find the location of the missing values\n",
        "sns.heatmap(training_data.isnull(), yticklabels = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0xaeb8950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAFtCAYAAABPxQIZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX2SiozlJKj4MAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0xaeb8210>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSy4JvocI-dd"
      },
      "source": [
        "Use the *training_data.describe()* function to check for **erroneous values**, this returns the summary statistics.   Check the *min* and *max* values, check if there are no strange values (eg. as mentioned above, negative number for ages or very large values)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh4wepopI-df",
        "outputId": "52dec9a1-9e43-4c8d-cd0c-4a83bb258569"
      },
      "source": [
        "# Check if there is erroneous data\n",
        "training_data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.385569</td>\n",
              "      <td>2.305524</td>\n",
              "      <td>29.471443</td>\n",
              "      <td>0.525366</td>\n",
              "      <td>0.383315</td>\n",
              "      <td>32.30542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.487004</td>\n",
              "      <td>0.836662</td>\n",
              "      <td>14.121908</td>\n",
              "      <td>1.104669</td>\n",
              "      <td>0.807466</td>\n",
              "      <td>49.78204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.92500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.45420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.13750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.32920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Survived      Pclass         Age  Siblings/Spouses Aboard  \\\n",
              "count  887.000000  887.000000  887.000000               887.000000   \n",
              "mean     0.385569    2.305524   29.471443                 0.525366   \n",
              "std      0.487004    0.836662   14.121908                 1.104669   \n",
              "min      0.000000    1.000000    0.420000                 0.000000   \n",
              "25%      0.000000    2.000000   20.250000                 0.000000   \n",
              "50%      0.000000    3.000000   28.000000                 0.000000   \n",
              "75%      1.000000    3.000000   38.000000                 1.000000   \n",
              "max      1.000000    3.000000   80.000000                 8.000000   \n",
              "\n",
              "       Parents/Children Aboard       Fare  \n",
              "count               887.000000  887.00000  \n",
              "mean                  0.383315   32.30542  \n",
              "std                   0.807466   49.78204  \n",
              "min                   0.000000    0.00000  \n",
              "25%                   0.000000    7.92500  \n",
              "50%                   0.000000   14.45420  \n",
              "75%                   0.000000   31.13750  \n",
              "max                   6.000000  512.32920  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRxSyD-KI-dj"
      },
      "source": [
        "The expected values are checked **categorical variable** (eg. Pclass only 1-2-3). The **unique values** are collected , using *.unique* function. **Discrete values** must be checked ( one cannot have 1.5 Parent/Children aboard)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IibADXuwI-dk",
        "outputId": "db0696d7-686d-4093-b626-262b34f21952"
      },
      "source": [
        "# Get the unique values of different coloumns\n",
        "print(training_data.Survived.unique())\n",
        "print(training_data.Pclass.unique())\n",
        "print(training_data['Siblings/Spouses Aboard'].unique())\n",
        "print(training_data['Parents/Children Aboard'].unique())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "[3 1 2]\n",
            "[1 0 3 4 2 5 8]\n",
            "[0 1 2 5 3 4 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzOOrn-8I-do"
      },
      "source": [
        "There are **no missing values, nor erroneous values**.\n",
        "\n",
        "It is worth checking for duplicates within columns which is simple using pandas and also take care of entire repeated columns this is prevalent when multiple columns are added or removed from the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzHvsF66I-dp"
      },
      "source": [
        "## 1.3  Exploratory data analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k45NPjYrI-dq"
      },
      "source": [
        "The **exploratory data analysis** is performed. It involves looking at  **summary statistics**, and the data using **visual methods** (such as box plot, scatter plot, histogram ect). The data must be understood to select the appropriate plot. \n",
        "\n",
        "*Training_data.describe()* is used,  it can be seen which attributes are continuous, which are categorical and also a feel for the data and the spread of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V7kPUXqI-dq",
        "outputId": "c41841b6-01e3-4f8b-d5f2-40521644fae9"
      },
      "source": [
        "# See the key features of the data \n",
        "training_data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.000000</td>\n",
              "      <td>887.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.385569</td>\n",
              "      <td>2.305524</td>\n",
              "      <td>29.471443</td>\n",
              "      <td>0.525366</td>\n",
              "      <td>0.383315</td>\n",
              "      <td>32.30542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.487004</td>\n",
              "      <td>0.836662</td>\n",
              "      <td>14.121908</td>\n",
              "      <td>1.104669</td>\n",
              "      <td>0.807466</td>\n",
              "      <td>49.78204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.92500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.45420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.13750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.32920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Survived      Pclass         Age  Siblings/Spouses Aboard  \\\n",
              "count  887.000000  887.000000  887.000000               887.000000   \n",
              "mean     0.385569    2.305524   29.471443                 0.525366   \n",
              "std      0.487004    0.836662   14.121908                 1.104669   \n",
              "min      0.000000    1.000000    0.420000                 0.000000   \n",
              "25%      0.000000    2.000000   20.250000                 0.000000   \n",
              "50%      0.000000    3.000000   28.000000                 0.000000   \n",
              "75%      1.000000    3.000000   38.000000                 1.000000   \n",
              "max      1.000000    3.000000   80.000000                 8.000000   \n",
              "\n",
              "       Parents/Children Aboard       Fare  \n",
              "count               887.000000  887.00000  \n",
              "mean                  0.383315   32.30542  \n",
              "std                   0.807466   49.78204  \n",
              "min                   0.000000    0.00000  \n",
              "25%                   0.000000    7.92500  \n",
              "50%                   0.000000   14.45420  \n",
              "75%                   0.000000   31.13750  \n",
              "max                   6.000000  512.32920  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmt_M0xhI-dv"
      },
      "source": [
        "Summary statistics for some attributes are checked. \n",
        "\n",
        "*Age* is chosen as an example of one continous variable, and *Sex* as a categorical variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MkVznQaI-dw",
        "outputId": "de2241e8-c076-4d36-9490-b7df25e8d017"
      },
      "source": [
        "# We can see the key summary statistics of our continous data \n",
        "training_data['Survived'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    887.000000\n",
              "mean       0.385569\n",
              "std        0.487004\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Xb3zo1I-dz",
        "outputId": "6c04e952-26b9-402a-d7fb-3d7374673684"
      },
      "source": [
        "# We can see the key summary statistics of our catagorical data \n",
        "training_data['Sex'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count      887\n",
              "unique       2\n",
              "top       male\n",
              "freq       573\n",
              "Name: Sex, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbF0ndFWI-d3",
        "outputId": "c5580f6b-d3ab-4eb2-b4fd-96488ddf14d6"
      },
      "source": [
        "# Number of rows \n",
        "print(\"# of passengers in training data: \" + str(len(training_data.index)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of passengers in training data: 887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cb7s92mI-d-"
      },
      "source": [
        "The seaborn package is excellent for plotting it makes use of the regular structure of the pandas datafarme and this simplifies plotting compared with matplotlib. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGr7MOknI-d_"
      },
      "source": [
        "Some plots that capture the key features of the data are displayed below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGq1CcGeI-eA",
        "outputId": "3edc6146-6d0b-4787-9479-849af7e3b0e6"
      },
      "source": [
        "# Number of people who survive vs died \n",
        "print(training_data[\"Survived\"].value_counts())\n",
        "sns.countplot(x = \"Survived\", data = training_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    545\n",
            "1    342\n",
            "Name: Survived, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0xac09a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIwQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0xac01ef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO7PZ89gI-eE"
      },
      "source": [
        "Number of survivors, grouped by gender."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt_UisqPI-eF",
        "outputId": "15f27e05-d2ee-4736-d51c-6cc18ba49cd7"
      },
      "source": [
        "# Number of surving gender \n",
        "# print(training_data[\"Sex\"].value_counts())\n",
        "# training_data.groupby([\"Survived\"]).count()\n",
        "sns.countplot(x = \"Survived\", hue = \"Sex\", data = training_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0xaf00ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngJAkZf1/kPytpvJk6uwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0xabc85d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC47SZ5OI-eI"
      },
      "source": [
        "Number of survivors, grouped by the class they travelled in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVnYgB9MI-eJ",
        "outputId": "36d6a765-378a-4551-dd07-ec74c29610a0"
      },
      "source": [
        "# Number of surving gender and Pclass \n",
        "sns.countplot(x = \"Survived\", hue = \"Pclass\", data = training_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0xaf1c450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0xaf25490>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yXgBoq6I-eN"
      },
      "source": [
        "Distribution of passanger age."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us_NGsxLI-eN",
        "outputId": "b8515709-ccde-4ab7-91b4-f8e68a4b22f8"
      },
      "source": [
        "# Histogram of the age of the passengers \n",
        "training_data[\"Age\"].plot.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0xaf89b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0xb051f90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKedc39bI-eR",
        "outputId": "bc6fd32e-773c-4cd5-fbb2-30366a0a99d7"
      },
      "source": [
        "# Histogram of the passenger class \n",
        "sns.countplot(x = \"Pclass\",data = training_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0xb50e5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0xb4e3630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41XUjyM8I-eU",
        "outputId": "3ae3cb89-2eab-4db2-db7e-399ef516aab1"
      },
      "source": [
        "# Box plot of Pclass and the age \n",
        "sns.boxplot( x = \"Pclass\", y = \"Age\", data = training_data )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0xb533cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0xaf004b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZnuytn6I-ea",
        "outputId": "b380c80e-7222-477d-b89d-e84df5cc4e3d"
      },
      "source": [
        "# Correlation matrix \n",
        "training_data.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Survived</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.336528</td>\n",
              "      <td>-0.059665</td>\n",
              "      <td>-0.037082</td>\n",
              "      <td>0.080097</td>\n",
              "      <td>0.256179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>-0.336528</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.391492</td>\n",
              "      <td>0.085026</td>\n",
              "      <td>0.020252</td>\n",
              "      <td>-0.548919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>-0.059665</td>\n",
              "      <td>-0.391492</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.297669</td>\n",
              "      <td>-0.193741</td>\n",
              "      <td>0.112329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <td>-0.037082</td>\n",
              "      <td>0.085026</td>\n",
              "      <td>-0.297669</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.414244</td>\n",
              "      <td>0.158839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <td>0.080097</td>\n",
              "      <td>0.020252</td>\n",
              "      <td>-0.193741</td>\n",
              "      <td>0.414244</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.215470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>0.256179</td>\n",
              "      <td>-0.548919</td>\n",
              "      <td>0.112329</td>\n",
              "      <td>0.158839</td>\n",
              "      <td>0.215470</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Survived    Pclass       Age  \\\n",
              "Survived                 1.000000 -0.336528 -0.059665   \n",
              "Pclass                  -0.336528  1.000000 -0.391492   \n",
              "Age                     -0.059665 -0.391492  1.000000   \n",
              "Siblings/Spouses Aboard -0.037082  0.085026 -0.297669   \n",
              "Parents/Children Aboard  0.080097  0.020252 -0.193741   \n",
              "Fare                     0.256179 -0.548919  0.112329   \n",
              "\n",
              "                         Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
              "Survived                               -0.037082                 0.080097   \n",
              "Pclass                                  0.085026                 0.020252   \n",
              "Age                                    -0.297669                -0.193741   \n",
              "Siblings/Spouses Aboard                 1.000000                 0.414244   \n",
              "Parents/Children Aboard                 0.414244                 1.000000   \n",
              "Fare                                    0.158839                 0.215470   \n",
              "\n",
              "                             Fare  \n",
              "Survived                 0.256179  \n",
              "Pclass                  -0.548919  \n",
              "Age                      0.112329  \n",
              "Siblings/Spouses Aboard  0.158839  \n",
              "Parents/Children Aboard  0.215470  \n",
              "Fare                     1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2IxgEhbI-eh"
      },
      "source": [
        "Correlation between attributes are displayed it is not advised to simply remove attributed solely based on this without understanding however it must be looked at closely since this will distort the results of our model. \n",
        "\n",
        "Consider serial multicollinearity, it would mean that than the rank of the matrix would be less that its dimension this would lead to problems when finding the inverse of the moment matrix (The problem will be ill posed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff6yAIUGI-ei",
        "outputId": "eae6ae5b-2ae7-4087-d1e2-33cf5d8657a6"
      },
      "source": [
        "training_data[training_data['Survived'] == 1].corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Survived</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.437923</td>\n",
              "      <td>-0.033300</td>\n",
              "      <td>0.021584</td>\n",
              "      <td>-0.538125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.437923</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.138740</td>\n",
              "      <td>-0.308689</td>\n",
              "      <td>0.181396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.033300</td>\n",
              "      <td>-0.138740</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.282498</td>\n",
              "      <td>0.122886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.021584</td>\n",
              "      <td>-0.308689</td>\n",
              "      <td>0.282498</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.116519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.538125</td>\n",
              "      <td>0.181396</td>\n",
              "      <td>0.122886</td>\n",
              "      <td>0.116519</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Survived    Pclass       Age  \\\n",
              "Survived                      NaN       NaN       NaN   \n",
              "Pclass                        NaN  1.000000 -0.437923   \n",
              "Age                           NaN -0.437923  1.000000   \n",
              "Siblings/Spouses Aboard       NaN -0.033300 -0.138740   \n",
              "Parents/Children Aboard       NaN  0.021584 -0.308689   \n",
              "Fare                          NaN -0.538125  0.181396   \n",
              "\n",
              "                         Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
              "Survived                                     NaN                      NaN   \n",
              "Pclass                                 -0.033300                 0.021584   \n",
              "Age                                    -0.138740                -0.308689   \n",
              "Siblings/Spouses Aboard                 1.000000                 0.282498   \n",
              "Parents/Children Aboard                 0.282498                 1.000000   \n",
              "Fare                                    0.122886                 0.116519   \n",
              "\n",
              "                             Fare  \n",
              "Survived                      NaN  \n",
              "Pclass                  -0.538125  \n",
              "Age                      0.181396  \n",
              "Siblings/Spouses Aboard  0.122886  \n",
              "Parents/Children Aboard  0.116519  \n",
              "Fare                     1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOn1hvVfI-em"
      },
      "source": [
        "The correlation between attributes, within classes. \n",
        "Attributes which are strongly correlated are candidates to be removed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "gl6BRXT8I-em",
        "outputId": "ee169044-c14d-4068-e027-710547115abe"
      },
      "source": [
        "# First entries of surviving passengers\n",
        "training_data[training_data['Survived'] == 0].head(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Owen Harris Braund</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. William Henry Allen</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. James Moran</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr. Timothy J McCarthy</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Master. Gosta Leonard Palsson</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. William Henry Saundercock</td>\n",
              "      <td>male</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Survived  Pclass                           Name   Sex   Age  \\\n",
              "0          0       3         Mr. Owen Harris Braund  male  22.0   \n",
              "4          0       3        Mr. William Henry Allen  male  35.0   \n",
              "5          0       3                Mr. James Moran  male  27.0   \n",
              "6          0       1         Mr. Timothy J McCarthy  male  54.0   \n",
              "7          0       3  Master. Gosta Leonard Palsson  male   2.0   \n",
              "12         0       3  Mr. William Henry Saundercock  male  20.0   \n",
              "\n",
              "    Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
              "0                         1                        0   7.2500  \n",
              "4                         0                        0   8.0500  \n",
              "5                         0                        0   8.4583  \n",
              "6                         0                        0  51.8625  \n",
              "7                         3                        1  21.0750  \n",
              "12                        0                        0   8.0500  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etf8iSlvI-ep"
      },
      "source": [
        "## 1.4 Preparing the data\n",
        "\n",
        "**Feature engineering**. Some features are not in the correct format and cannot be used in our logistic regression model.  \n",
        "\n",
        "String variables like the names of passengers provide no insight and do not have any predictive power so are removed. \n",
        "\n",
        "Some are useful but need to be transformed to **0-1 (binary)** variables such as Sex. Pandas is very helpful here as we can readily create dummy variables and add and remove attributes. In the literature this is known as feauture extraction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xuvC1XNI-eq"
      },
      "source": [
        "Changes made to the data:\n",
        "\n",
        "**1)** **Sex** is changed to a **binary variable  0-1 (where 0 is female and 1 is male)**, there are only two options and absence from one class implies presence in the other thus the inclusion of a single column is sufficient.\n",
        "\n",
        "**2)** For **Pclass** the same procedure was followed, but here there is **3 categories / different values**, so **2 columns of 0-1 values (if Pcl2 = 1, the passengers  travelled in 2nd class; for Pc2 = 1 they travelled in 2nd class; and if both Pcl1 = Pcl2 = 0 then they travelled in 1st class)** are neccassery.\n",
        "\n",
        "**3)**  Concatenate the new columns and drop those not suitable for the model.\n",
        "\n",
        "**4)**  Split the data into the class labels (survival column) and the passenger attributes. \n",
        "\n",
        "**5)**  To use the advantages of numpy **convert dataframe into numpy arrays** .\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sRrQI2qI-eq",
        "outputId": "ddad4127-834c-4bb1-dbfa-cc437c9bbc3b"
      },
      "source": [
        "# String to catagorical variables using dummies\n",
        "sex = pd.get_dummies(training_data[\"Sex\"], drop_first = True)\n",
        "Pcl = pd.get_dummies(training_data[\"Pclass\"], drop_first = True)\n",
        "\n",
        "# Add new columns to the data \n",
        "training_data = pd.concat([training_data,sex,Pcl], axis = 1)\n",
        "\n",
        "# Remove the string data \n",
        "training_data.drop([\"Name\",\"Sex\",\"Pclass\"], axis = 1, inplace = True)\n",
        "training_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Age</th>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <th>Fare</th>\n",
              "      <th>male</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \\\n",
              "0         0  22.0                        1                        0   7.2500   \n",
              "1         1  38.0                        1                        0  71.2833   \n",
              "2         1  26.0                        0                        0   7.9250   \n",
              "3         1  35.0                        1                        0  53.1000   \n",
              "4         0  35.0                        0                        0   8.0500   \n",
              "5         0  27.0                        0                        0   8.4583   \n",
              "6         0  54.0                        0                        0  51.8625   \n",
              "7         0   2.0                        3                        1  21.0750   \n",
              "8         1  27.0                        0                        2  11.1333   \n",
              "9         1  14.0                        1                        0  30.0708   \n",
              "\n",
              "   male  2  3  \n",
              "0     1  0  1  \n",
              "1     0  0  0  \n",
              "2     0  0  1  \n",
              "3     0  0  0  \n",
              "4     1  0  1  \n",
              "5     1  0  1  \n",
              "6     1  0  0  \n",
              "7     1  0  1  \n",
              "8     0  0  1  \n",
              "9     0  1  0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_U1Q_nlI-et"
      },
      "source": [
        "# Generate the matrices from the Titanic data\n",
        "titanic_x = training_data.drop(\"Survived\", axis=1)\n",
        "titanic_y = training_data[\"Survived\"] \n",
        "\n",
        "# Convert dataframe to numpy array\n",
        "# X_old = titanic_x.to_numpy()\n",
        "# y = titanic_y.to_numpy()\n",
        "X_old = titanic_x.values\n",
        "y     = titanic_y.values\n",
        "\n",
        "# Take from np array the identifier \n",
        "Age   = X_old[:,0]\n",
        "Sibsp = X_old[:,1]\n",
        "Pch   = X_old[:,2]\n",
        "Fare  = X_old[:,3]\n",
        "Sex   = X_old[:,4]\n",
        "Pcl2  = X_old[:,5]\n",
        "Pcl3  = X_old[:,6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x-zpRqPI-ex"
      },
      "source": [
        "**Standardization** is useful in machine learning as it brings everything onto the **same scale**. It reduces the effect of a single attribute on the model. It means that our cost function is more smooth so our gradient descent algorithm will work faster. \n",
        "\n",
        "The technical detail of this is that the data should be heterogeneous, for a model where the attributes are of different types and are on different scales an advance technique is random forest this method works well with such data (where we have categorical  and continuous data). \n",
        "\n",
        "Some consideration should be given to standardization when using dummy variables. There are differences of opinion on this matter some say that non dummy variables should be standardized twice we found this to not significantly change our result. In a model with more complicated relationships this could have an effect.\n",
        "\n",
        "Age, Fare, Sex, and the newly created Pcl2 and Pcl3 were standardised.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhaNPqITI-ex"
      },
      "source": [
        "def standardise(x):\n",
        "    \"\"\"Standardize the original data set.\"\"\"\n",
        "    mean_x = np.mean(x, axis=0)\n",
        "    x = x - mean_x\n",
        "    std_x = np.std(x, axis=0)\n",
        "    x = x / std_x\n",
        "    return x, mean_x, std_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLzbV8roI-e0"
      },
      "source": [
        "Feature selection is a task in itself. It is an important part of machine learning but beyond the scope of this project. Here all features are chosen this can lead to problems.\n",
        "\n",
        "Including those features that are not contributing or redundant in the model will cause randomness or noise to be attributed to these features it can also lead to numerical instability. It is possible the model will overfit and our solution will not generalize. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBrS59jVI-e0"
      },
      "source": [
        "# Select which variable you wish to perform the logisitc regression \n",
        "X = np.c_[Age,Sibsp,Pch,Fare,Sex,Pcl2,Pcl3]\n",
        "\n",
        "# Consider the 1,0 variables and standardization\n",
        "\n",
        "# Standardize the data \n",
        "x, mean_x, std_x = standardise(X)\n",
        "\n",
        "# Avoid double scalar as python works with nd arrays \n",
        "y = y.reshape(len(y),1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rteWeFWYI-e3"
      },
      "source": [
        "It is not sufficient to minimize the error for the model on the data we train we must also minimize the error on the testing data, it is possible we overfit our model and it predicts the data it was trained on well but does not generalize.\n",
        "\n",
        "K fold Cross validation ensures that the accuracy of the model should not differ significantly for training or testing sets but this is not required for a basic data set such as this one. In titanic there is no specific testing data but we separate some data from the dataset and use this as our testing set this is common practise. Here we choose k to just be 2. This is also why it is called out of sample testing.\n",
        "\n",
        "Reducing the variance within both samples is the aim. Choosing the split ratio is a difficult choice and depends on factors such as the size of the dataset, also one should consider the complexity of the function (typically this is unknown) when choosing the training testing split a more complex function will need more samples. It is useful to consider the number of points required to accurately interpolate a polynomial increases with the degree.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZN2teCiI-e4"
      },
      "source": [
        "# Function to split the data into testing and training sets \n",
        "\n",
        "def split_data(x, y, ratio, myseed=1):\n",
        "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
        "    # set seed\n",
        "    np.random.seed(myseed)\n",
        "    # generate random indices\n",
        "    num_row = len(y)\n",
        "    indices = np.random.permutation(num_row)\n",
        "    index_split = int(np.floor(ratio * num_row))\n",
        "    index_tr = indices[: index_split]\n",
        "    index_te = indices[index_split:]\n",
        "    # create split\n",
        "    x_tr = x[index_tr]\n",
        "    x_te = x[index_te]\n",
        "    y_tr = y[index_tr]\n",
        "    y_te = y[index_te]\n",
        "    return x_tr, x_te, y_tr, y_te"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkV808B9I-e6"
      },
      "source": [
        "This function builds a polynomial up to a specified degree. This allows augmentation  of the input and returns a polynomial basis function. The issue of overfitting will now need to be dealt with however if a complex relationship exists we will importantly be able to capture this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJuL0BYCI-e7"
      },
      "source": [
        "# Polynomial basis building function \n",
        "\n",
        "def build_poly(x, degree):\n",
        "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
        "    poly = np.ones((len(x), 1))\n",
        "    for deg in range(1, degree+1):\n",
        "        poly = np.c_[poly, np.power(x, deg)]\n",
        "    return poly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKIJ1cAjI-e-"
      },
      "source": [
        "## 1.5 Model building "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHTJlFMuI-e_"
      },
      "source": [
        "This is a probabilistic classifier. Using the discriminative approach we fit it to the model of the form p(y,x). \n",
        "\n",
        "This is a linear classifier, the difference between this and non-linear classifiers is that we only consider linear combinations of the features. Logistic regression and softmax regression are both linear classifiers. \n",
        "\n",
        "The typical example given for when linear classifiers fail is with XOR function the where the data it is not linearly separable.\n",
        "\n",
        "Supervised machine learning is where there are pairs of values (our input and output) we try to find the relationship between via some function the difference between this and unsupervised machine learning is that there are no labels and we do not know the relationship we are looking for. \n",
        "\n",
        "It is evident that the features age, fare ect are used to see if they affect a person's chance of survival (class labels).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHwGJ_QzI-fA"
      },
      "source": [
        "### 1.5.1 Sigmoid function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btDhyzeSI-fA"
      },
      "source": [
        "Logistic regression is a special case of normal regression where the values that we want to predict are **categorical**. In the **binary** case they take only two values. Linear regression will fail here because the MSE cost function is not suited for this purpose. For example imbalanced classes will have a disproportionate effect on our weights. \n",
        "\n",
        "Logistic regression differs in that predicted values are mapped to a number between [0,1] which is the probability of belonging to a specific class. \n",
        "\n",
        "This is done with the **sigmoid function**. We choose a **threshold in our model of 1/2** to determine which class an item belongs to using weights we find using the data based on some attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXx5SzYpI-fB"
      },
      "source": [
        "$$\n",
        "\\sigma( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RpsngG3nI-fC"
      },
      "source": [
        "# sigmoid function \n",
        "\n",
        "def sigmoid(t):\n",
        "    s = 1/(1+np.exp(-t))\n",
        "    return s\n",
        "    raise NotImplementedError           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLtYRy1gI-fF"
      },
      "source": [
        "The loss function of MSE is unsuitable, a new function for the logistic regression is derived using the **Maximum likelihood estimation technique**. \n",
        "\n",
        "The analytic method we use for linear regression is no longer possible (not that this is advisable even when it is possible, numerical methods are preferred), we cannot write a formulae to minimize the loss in a closed form this is because of the sigmoid function. For this reason a method where weights are iteratively updated to find the optimum is implemented. \n",
        "\n",
        "The losses are useful to evaluate the performance of our optimization algorithm. Losses can be plot at each iteration to see the convergence and can be used as a visualize check for our learning rate. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brWwkut4I-fF"
      },
      "source": [
        "$$NLL(w)= - \\sum_{i=1}^{N}\\left[y_i\\log{\\mu_i}+(1-y_i)\\log{(1-\\mu_i)} \\right] $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "pwoUx9F4I-fG"
      },
      "source": [
        "# Loss function \n",
        "\n",
        "def calculate_loss(y, tx, w):   \n",
        "    loss = np.log(1 + np.exp(tx.dot(w))) - y * (tx.dot(w))\n",
        "    Loss = np.mean(loss)\n",
        "    return Loss \n",
        "    raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF4Rbg7SI-fJ"
      },
      "source": [
        "l2 regularization must be preferred  over standard logistic  regression as it helps avoid overfitting. It means the model we create is less brittle and will perform similarly  on both the testing and training data. \n",
        "\n",
        "Two advance methods that work to minimize bias-variance trade off are mixture models and ensemble learning. \n",
        "The question of selecting the \"correct\" bias term still stands later cross validation will be explored using this alpha can be determined. \n",
        "\n",
        "Minor alterations must be made to our loss and cost functions but in this case they are inconsequential with regards to gradient descent as the regularization term is differentiable. \n",
        "\n",
        "If interested in normal logistic regression simply force the alpha value to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MfLMiUj2I-fJ"
      },
      "source": [
        "# Function that returns loss and grad \n",
        "\n",
        "def penalised_logistic_regression(y, tx, w, alpha):\n",
        "    loss = np.log(1 + np.exp(tx.dot(w))) - (y * (tx.dot(w))) + (0.5 * alpha * la.norm(w))\n",
        "    Loss = np.mean(loss)\n",
        "    grad = np.matmul(tx.T,(sigmoid(tx.dot(w))-y)) + alpha*w\n",
        "    return Loss, grad\n",
        "    raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9qfC6-tI-fO"
      },
      "source": [
        "$$ g = \\frac{d}{dw}f(w) = \\sum_{i}(\\mu_i-y_i)x_i=X^T(\\mu-y)   $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbOCIx7RI-fP"
      },
      "source": [
        "The weights iteratively update via the method of gradient descent\n",
        "\n",
        "The negative derivative of the loss function is our search direction. This is the simplest method in convex optimization and guarantees global convergence under some conditions (differentiability and Lipchitz continuousness).\n",
        "\n",
        "Choosing the hyperparameter of the learning rate is a non-trivial task when using gradient descent.\n",
        "\n",
        "There are several techniques such as the the method of exact line search to find this value. We could also use the heavy ball method which includes a momentum term that increases the rate of convergence as it decreases zigzagging to find the learning rate. Here trial and error is used. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RUjhLjWzI-fP"
      },
      "source": [
        "# One update of the gradient descent algorithm\n",
        "\n",
        "def learning_by_penalised_gradient(y, tx, w, tau, alpha):\n",
        "    loss,grad = penalised_logistic_regression(y, tx, w, alpha)\n",
        "    w = w - tau*(grad)\n",
        "    return loss, w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8Xguwr3I-fU"
      },
      "source": [
        "The initial weights for the model are 0 but they can start from a random number. Also selected is a threshold value such that if the difference between two successive iterations is not met the iterations continue until some max iterations that we specifiy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "35Tn1xpoI-fW"
      },
      "source": [
        "# Regularized logistic regression\n",
        "\n",
        "def logistic_regression_penalised_gradient_descent(y, tx, alpha): # ridge_regression\n",
        "    # init parameters\n",
        "    max_iter = 10000\n",
        "    tau = 0.01\n",
        "    threshold = 1e-8\n",
        "    losses = []\n",
        "    w = np.zeros((tx.shape[1], 1))\n",
        "\n",
        "    # start the logistic regression\n",
        "    for iter in range(max_iter):\n",
        "        # get loss and update w.\n",
        "        loss, w = learning_by_penalised_gradient(y, tx, w, tau, alpha)    \n",
        "        \n",
        "        losses.append(loss)\n",
        "        if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n",
        "            break\n",
        "    return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAYKkCBNI-fd"
      },
      "source": [
        "The accuracy (more accurately misclassification rate) is calculated. This is not the only metric which is important, in fact it is very poor and affected by imbalanced classes and other issues,  measures such as precision and recall are far more useful but here the models performance is considered solely  on the basis of its predictive ability. \n",
        "\n",
        "Identifying the effects of individual attributes is also possible but one would need to consider subsets of all features.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "T0lR4NgfI-fd"
      },
      "source": [
        "# Function to calculate the accuracy of our classifier with 0.5 decision boundary \n",
        "\n",
        "def compute_accuracy(y, tx, w):\n",
        "       \n",
        "        est_y = np.array(sigmoid(tx.dot(w)))\n",
        "        \n",
        "        est_y = est_y > 0.5\n",
        "        est_y = est_y.astype(int)\n",
        "        \n",
        "        acc_y = est_y == y\n",
        "        acc_y = acc_y.astype(int)\n",
        "        \n",
        "        len_y = float(len(y))\n",
        "        accuracy = sum(acc_y)\n",
        "        \n",
        "        accuracy = accuracy/len_y\n",
        "       \n",
        "        return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "y7eHpEsjI-fh"
      },
      "source": [
        "# Function to calculate the confusion matrix \n",
        "# Calculate the the number of false positive, false negative , true positive, true negative \n",
        "# Then package into a numpy array\n",
        "\n",
        "def compute_tp(y,tx,w):\n",
        "     \n",
        "        est_y = np.array(sigmoid(tx.dot(w)))\n",
        "        \n",
        "        est_y = est_y > 0.5\n",
        "        est_y = est_y.astype(int)\n",
        "        tp = est_y + y\n",
        "        tp = tp == 2\n",
        "        tp = tp.astype(int)\n",
        "        tp = sum(tp)\n",
        "           \n",
        "        return tp \n",
        "    \n",
        "def compute_tn(y,tx,w):\n",
        "     \n",
        "        est_y = np.array(sigmoid(tx.dot(w)))\n",
        "        \n",
        "        est_y = est_y > 0.5\n",
        "        est_y = est_y.astype(int)\n",
        "        tn = est_y + y\n",
        "        tn = tn == 0\n",
        "        tn = tn.astype(int)     \n",
        "        tn = sum(tn)\n",
        "            \n",
        "        return tn     \n",
        "\n",
        "def compute_fn(y,tx,w):\n",
        "    \n",
        "        est_y = np.array(sigmoid(tx.dot(w)))\n",
        "        \n",
        "        est_y = est_y > 0.5\n",
        "        est_y = est_y.astype(int)\n",
        "        fn1 = est_y == 0\n",
        "        fn2 = y == 1\n",
        "        fn1 = fn1.astype(int)       \n",
        "        fn2 = fn2.astype(int)\n",
        "        fn = fn1 + fn2\n",
        "        fn = fn == 2\n",
        "        fn = sum(fn)\n",
        "        \n",
        "        return fn\n",
        "    \n",
        "def compute_fp(y,tx,w):\n",
        "    \n",
        "        est_y = np.array(sigmoid(tx.dot(w)))\n",
        "        \n",
        "        est_y = est_y > 0.5\n",
        "        est_y = est_y.astype(int)\n",
        "        fp1 = est_y == 1\n",
        "        fp2 = y == 0\n",
        "        fp1 = fp1.astype(int)       \n",
        "        fp2 = fp2.astype(int)\n",
        "        fp = fp1 + fp2\n",
        "        fp = fp == 2\n",
        "        fp = sum(fp)\n",
        "        \n",
        "        return fp\n",
        "    \n",
        "def confusion(y,tx,w):\n",
        "        tp = compute_tp(y,tx,w) \n",
        "        tn = compute_tn(y,tx,w)\n",
        "        fn = compute_fn(y,tx,w)\n",
        "        fp = compute_fp(y,tx,w)\n",
        "        confusion = np.array([tp,fp,fn,tn])\n",
        "        confusion = confusion.reshape(2,2)\n",
        "        return confusion \n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6EGYDGrI-fl"
      },
      "source": [
        "Hyperparameters are the model parameters which cannot be learned from the data. \n",
        "\n",
        "Using ridge regression we hope to find the optimal parameters by considering the variance - bias trade off this is a significant part in many models. The regularization term helps achieve this essentially the function should be of the correct complexity to capture the relationship between predictor class id but without fitting to the random noise. \n",
        "\n",
        "Here we just use grid search to find the optimal value of alpha. What is important is that we are looking in the correct range it is likely here we are not. \n",
        "\n",
        "There are several techniques including advance genetic algorithms as well as calculating values for pairs of hyperparameters usually in a grid form that should be explored. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "D51H2Ga2I-fm"
      },
      "source": [
        "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
        "    \"\"\"ridge regression demo.\"\"\"\n",
        "    \n",
        "    # define parameter\n",
        "    alphas = np.logspace(-5, 0, 15)\n",
        "    \n",
        "    # split data\n",
        "    x_tr, x_te, y_tr, y_te = split_data(x, y, ratio, seed)\n",
        "    \n",
        "    # form tx\n",
        "    tx_tr = build_poly(x_tr, degree)\n",
        "    tx_te = build_poly(x_te, degree)\n",
        "    \n",
        "    # ridge regression with different lambda\n",
        "    acc_tr = []\n",
        "    acc_te = []\n",
        "    weights = [] \n",
        "    \n",
        "    for ind, alpha in enumerate(alphas):\n",
        "       \n",
        "    # ridge regression\n",
        "        weight = logistic_regression_penalised_gradient_descent(y_tr, tx_tr, alpha)\n",
        "        acc_tr.append(compute_accuracy(y_tr, tx_tr, weight))\n",
        "        acc_te.append(compute_accuracy(y_te, tx_te, weight))\n",
        "        weights.append(weight)\n",
        "        weight_optimal = weights[np.argmax(acc_te)]\n",
        "  \n",
        "    return np.c_[np.array(acc_tr),np.array(acc_te),alphas], weight_optimal,confusion(y_te,tx_te,weight_optimal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Qlq7qcKwI-fp"
      },
      "source": [
        "# Additional function that was created due to a problem encountered in the notebook not encountered in spyder \n",
        "\n",
        "def ridge_regression_demon(x, y, degree, ratio, seed):\n",
        "    \"\"\"ridge regression demo.\"\"\"\n",
        "    \n",
        "    # define parameter\n",
        "    alphas = np.logspace(-5, 0, 15)\n",
        "    \n",
        "    # split data\n",
        "    x_tr, x_te, y_tr, y_te = split_data(x, y, ratio, seed)\n",
        "    \n",
        "    # form tx\n",
        "    tx_tr = build_poly(x_tr, degree)\n",
        "    tx_te = build_poly(x_te, degree)\n",
        "    \n",
        "    # ridge regression with different lambda\n",
        "    acc_tr = []\n",
        "    acc_te = []\n",
        "    weights = [] \n",
        "    \n",
        "    for ind, alpha in enumerate(alphas):\n",
        "       \n",
        "    # ridge regression\n",
        "        weight = logistic_regression_penalised_gradient_descent(y_tr, tx_tr, alpha)\n",
        "        acc_tr.append(compute_accuracy(y_tr, tx_tr, weight))\n",
        "        acc_te.append(compute_accuracy(y_te, tx_te, weight))\n",
        "        weights.append(weight)\n",
        "        weight_optimal = weights[np.argmax(acc_te)]\n",
        "  \n",
        "    return np.c_[np.array(acc_tr),np.array(acc_te),alphas], weight_optimal,compute_accuracy(y_te,tx_te,weight_optimal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "vUz6TUrsI-fr"
      },
      "source": [
        "## 1.6 Evaluation / Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcqW_nKNI-fs"
      },
      "source": [
        "**Test model and adjust the hyperparameters to get the best misclassification rate**. Increasing model complexity has little effect of the models accuracy. The polynomial basis function of degree one seems to work best. \n",
        "\n",
        "Refining of the hyperparaters is time consuming and given the limited benefit it can be concluded that time spent better preparing the data, extracting more useful features or even collecting more where possible. \n",
        "\n",
        "Selecting the value of alpha correctly **should** prevent overfitting of the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tBRmz-jI-fs"
      },
      "source": [
        "### READ ME\n",
        "\n",
        "The values in the code snippet below will not update unless you choose to **restart and run all**\n",
        "SEE BELOW\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bb8xOQqI-ft",
        "outputId": "304bb523-fc43-4df8-bd40-e46b91cec1b1"
      },
      "source": [
        "# Do not use this unless you run the notebook from the start \n",
        "\n",
        "seed = 143          # Seed value allows us to reproduce our results\n",
        "degree = 1          # Degree of the polynomial\n",
        "split_ratio = 0.9   # Testing training split \n",
        "\n",
        "res,weight_optimal,confusion = ridge_regression_demo(x, y, degree, split_ratio, seed)\n",
        "res # 1st column training acc 2nd test acc 3rd alpha value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  7.38095238e-01,   8.20224719e-01,   1.00000000e-05],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   2.27584593e-05],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   5.17947468e-05],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   1.17876863e-04],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   2.68269580e-04],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   6.10540230e-04],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   1.38949549e-03],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   3.16227766e-03],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   7.19685673e-03],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   1.63789371e-02],\n",
              "       [  7.38095238e-01,   8.20224719e-01,   3.72759372e-02],\n",
              "       [  7.36842105e-01,   8.20224719e-01,   8.48342898e-02],\n",
              "       [  7.36842105e-01,   8.20224719e-01,   1.93069773e-01],\n",
              "       [  7.35588972e-01,   8.20224719e-01,   4.39397056e-01],\n",
              "       [  7.30576441e-01,   8.20224719e-01,   1.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVqJfSKUI-fx"
      },
      "source": [
        "The sign of the optimal weights shows how each attributes contributes to the probability of surviving the accident:\n",
        "* **Negative value for the age** shows the **older the passenger the less probability he/she had to survive**\n",
        "* For **Siblings and Parents also has negative value**, so the **more relative the passenger had, the less probability he/she had to survive**\n",
        "* **Fare had positive value**, so the **more the ticket cost, the more chance he/she had to survive**\n",
        "* **Negative value** for gender means **female had better chance to survive** (since gender=0 is female)\n",
        "*  For travel class, our model predicts, that the **higher class you travel in the higher chance you survive**.\n",
        "\n",
        "These results are in accordance with the explanatory data analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqJVG3NBI-fx",
        "outputId": "28b59202-0474-4c67-939e-06687cb7b1f4"
      },
      "source": [
        "# Optimal weight\n",
        "weight_optimal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.62722969],\n",
              "       [-0.42325944],\n",
              "       [-0.74256709],\n",
              "       [-0.33392409],\n",
              "       [ 0.18696559],\n",
              "       [-1.27346298],\n",
              "       [-0.24563836],\n",
              "       [-1.6382981 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjcwx5llI-f0",
        "outputId": "d043e7bb-3093-46f0-c42a-b7710e7e1680"
      },
      "source": [
        "# Confusion matrix\n",
        "confusion "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24, 10],\n",
              "       [ 6, 49]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRLNAgudI-f4"
      },
      "source": [
        "The confusion matrix. A special type of contingency table. From here quantities used in statistical  tests can be calculated such as, precision, recall and f value.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW0zhaQzI-f4"
      },
      "source": [
        "### READ ME\n",
        "\n",
        "The values in the code snippet below will update without restarting the kernal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQROBBg_I-f6",
        "outputId": "b429b018-81f6-4419-b60a-60836b8cbf59"
      },
      "source": [
        "# If you wish to change values use this function it will update\n",
        "\n",
        "seed = 145          # Seed value allows us to reproduce our results\n",
        "degree = 1          # Degree of the polynomial\n",
        "split_ratio = 0.9   # Testing training split \n",
        "\n",
        "res,weight_optimal,accuracy = ridge_regression_demon(x, y, degree, split_ratio, seed)\n",
        "res # 1st column training acc 2nd test acc 3rd alpha value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  7.46867168e-01,   7.41573034e-01,   1.00000000e-05],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   2.27584593e-05],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   5.17947468e-05],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   1.17876863e-04],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   2.68269580e-04],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   6.10540230e-04],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   1.38949549e-03],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   3.16227766e-03],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   7.19685673e-03],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   1.63789371e-02],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   3.72759372e-02],\n",
              "       [  7.46867168e-01,   7.41573034e-01,   8.48342898e-02],\n",
              "       [  7.45614035e-01,   7.30337079e-01,   1.93069773e-01],\n",
              "       [  7.38095238e-01,   7.30337079e-01,   4.39397056e-01],\n",
              "       [  7.34335840e-01,   7.19101124e-01,   1.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCKXwVulI-f8",
        "outputId": "13897254-9148-4910-ff22-6f7863213921"
      },
      "source": [
        "# Accuracy\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.74157303])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poxOVEioI-gA",
        "outputId": "3cfa132a-d0f3-411c-df95-684576193989"
      },
      "source": [
        "# Optimal weight\n",
        "weight_optimal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.57049938],\n",
              "       [-0.38783146],\n",
              "       [-0.73905477],\n",
              "       [-0.29267848],\n",
              "       [ 0.31295878],\n",
              "       [-1.27285398],\n",
              "       [-0.23408539],\n",
              "       [-1.590352  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rsiVlRXI-gF"
      },
      "source": [
        "When evaluating our models accuracy it is useful to consider the accuracy of an untrained model. Most people die so an accuracy of around 62 % should be expected (accuracy of an untrained model). \n",
        "\n",
        "Using a linear classifier of this nature with such data preparation while the accuracy will vary from sample to \n",
        "sample but something around 80% can be expected. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VnulxCfI-gF"
      },
      "source": [
        "Feature selection is an important part of model building at this early stage to include all the variables as the tools and knowledge to reliably choose and make judgements about which attributes  are significant are beyond the scope of this task. \n",
        "\n",
        "A possible next step is to use a method where feature selection is part of the algorithm such as the L1 regularization  or lasso. \n",
        "L1 regularization makes use of sparsity to indicate to use which features  are significant in our model. \n",
        "\n",
        "There are a large number of possible  combinations of features $2^n$ where n is the number of features for a small number we can see selecting a subset of features using an exhaustive  search will not be computationally  tractable. \n",
        "\n",
        "One can consider the statistical significance of features but these will change depending on the features they appear alongside. This further demonstrates the inexact nature of machine learning and why it is reliant on heuristics and metaheuristics. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHVFzyXzI-gG"
      },
      "source": [
        "Advanced optimization methods we could use instead of gradient descent is the faster converging newton method however due to numerical instability  of inversion stochastic gradient descent and variations of it such as adam and rmsprop are commonly used. Some of these adaptively change  the learning rate. With these however there is no guarantee of convergence and a choice of the other hyperparameters is still required. As model and algorithm complexity is increased it becomes harder to understand and interpret the model we are using. Using a simple model in most cases is best.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2_lx1goI-gG"
      },
      "source": [
        "An interesting idea in computation is the no free lunch theorem. It summarises many of the difficulties faced in machine learning and why selecting the correct model and parameters is seen to be more an art than an exact science."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpp-vPUWI-gG"
      },
      "source": [
        "To conclude logistic regression was used to solve a binary classification problem. Difficulties were faced mainly in determining the appropriate hyperparameters and feature selection, possible solutions to both have been outlined in the body of the report.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjQRX36gI-gJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}